{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meixinyu/anaconda3/envs/easysteer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-13 22:12:29 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vllm\n",
    "import json\n",
    "from easysteer.hidden_states import get_all_hidden_states\n",
    "from vllm import LLM\n",
    "\n",
    "from easysteer.steer import extract_pca_control_vector,StatisticalControlVector\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    "\n",
    "# vector_path = \"vectors/thinking_switch_pca_MATH-500.gguf\" #MATH-500\n",
    "\n",
    "\n",
    "num_question = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../temp/test.jsonl\" #MATH-500\n",
    "# file_path = \"../../temp/test_gsm8k.jsonl\" #GSM8K\n",
    "\n",
    "vector_path = \"MATH500.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_list = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            if line_count >= num_question:\n",
    "                break\n",
    "            stripped_line = line.strip()\n",
    "            if not stripped_line:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(stripped_line)\n",
    "                if \"problem\" in data:\n",
    "                    problem_list.append(data[\"problem\"])\n",
    "                    line_count += 1\n",
    "                elif \"question\" in data:\n",
    "                    problem_list.append(data[\"question\"])\n",
    "                    line_count += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"skip: {line[:50]}...\")\n",
    "                continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"{str(e)}\")\n",
    "# problem_list = [\"Find the roots of $(x - 3)^3 + (x -7)^3 = (2x - 10)^3.$\",\"A regular hexagon can be divided into six equilateral triangles. If the perimeter of one of the triangles is 21 inches, what is the perimeter, in inches, of the regular hexagon?\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_thinking = [\n",
    "    \"Walk me through your complete reasoning process step by step. Output as many procedures as you can.\"\n",
    "]\n",
    "\n",
    "fast_thinking = [\n",
    "    \"Direct answer only.\"\n",
    "]\n",
    "\n",
    "len_slow=len(slow_thinking)\n",
    "len_fast=len(fast_thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$Walk me through your complete reasoning process step by step. Output as many procedures as you can.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|im_start|>user\n",
      "Let $a$ be a positive real number such that all the roots of\n",
      "\\[x^3 + ax^2 + ax + 1 = 0\\]are real.  Find the smallest possible value of $a.$Walk me through your complete reasoning process step by step. Output as many procedures as you can.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|im_start|>user\n",
      "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$Direct answer only.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for prob in problem_list:\n",
    "    for req in slow_thinking:\n",
    "        texts.append(f\"\"\"<|im_start|>user\n",
    "{prob}{req}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\")\n",
    "\n",
    "for prob in problem_list:\n",
    "    for req in fast_thinking:\n",
    "        texts.append(f\"\"\"<|im_start|>user\n",
    "{prob}{req}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\")\n",
    "print(texts[0])\n",
    "print(texts[num_question*len_slow-1])\n",
    "print(texts[num_question*len_slow])\n",
    "with open(\"111.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text + \"\\n\")  # 每个元素后加换行符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-13 22:12:38 [config.py:1472] Using max model len 32768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 22:12:38,465\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-13 22:12:38 [config.py:4615] Only \"last\" pooling supports chunked prefill and prefix caching; disabling both.\n",
      "INFO 07-13 22:12:38 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250712) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-13 22:12:39 [cuda.py:351] Using Flash Attention backend.\n",
      "INFO 07-13 22:12:39 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-13 22:12:39 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.08it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-13 22:12:41 [default_loader.py:272] Loading weights took 1.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-13 22:12:41 [model_runner.py:1255] Model loading took 2.8876 GiB and 1.150251 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 40/40 [00:00<00:00, 2337.25it/s]\n",
      "Processed prompts: 100%|██████████| 40/40 [00:00<00:00, 58.66it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_path,task=\"reward\",tensor_parallel_size=1)\n",
    "\n",
    "all_hidden_states, outputs = get_all_hidden_states(llm, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PCA directions:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PCA directions: 100%|██████████| 28/28 [00:00<00:00, 531.46it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "control_vector = extract_pca_control_vector(\n",
    "    all_hidden_states=all_hidden_states,\n",
    "    positive_indices=list(range(num_question*len_slow)), \n",
    "    negative_indices=list(range(num_question*len_slow,num_question*(len_slow+len_fast))),\n",
    "    model_type=\"qwen2.5\",\n",
    "    token_pos=-1,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='pca', directions={0: memmap([-0.01113699, -0.06029188,  0.04215517, ..., -0.01189059,\n",
      "        -0.02577175, -0.01083255], shape=(1536,), dtype=float32), 1: memmap([ 0.02075267, -0.00759126,  0.01752456, ..., -0.01258039,\n",
      "        -0.03163083, -0.04065328], shape=(1536,), dtype=float32), 2: memmap([ 0.0100673 , -0.0234082 ,  0.02484847, ...,  0.06437913,\n",
      "        -0.01141085, -0.05111764], shape=(1536,), dtype=float32), 3: memmap([-0.01157416, -0.00161835,  0.04929598, ...,  0.02504394,\n",
      "        -0.02055443, -0.04532089], shape=(1536,), dtype=float32), 4: memmap([ 0.00013692,  0.01033693,  0.02944114, ...,  0.03095547,\n",
      "        -0.03417241, -0.00300148], shape=(1536,), dtype=float32), 5: memmap([-0.00319834,  0.04855272,  0.02122804, ..., -0.01298449,\n",
      "        -0.04043267, -0.03302082], shape=(1536,), dtype=float32), 6: memmap([ 0.01014982,  0.00519793,  0.03920706, ..., -0.01955185,\n",
      "         0.04191752,  0.01931267], shape=(1536,), dtype=float32), 7: memmap([-0.02254921,  0.00715113, -0.02151527, ..., -0.00314058,\n",
      "        -0.02238353,  0.0175124 ], shape=(1536,), dtype=float32), 8: memmap([ 1.3144190e-02, -7.0782881e-03,  6.5297284e-03, ...,\n",
      "        -7.1450646e-05, -6.7214891e-03,  2.3428479e-02],\n",
      "       shape=(1536,), dtype=float32), 9: memmap([-0.00225663, -0.02022968, -0.00601694, ..., -0.0236897 ,\n",
      "        -0.03319987,  0.01383019], shape=(1536,), dtype=float32), 10: memmap([ 0.00086837, -0.0197641 , -0.01993287, ...,  0.01880435,\n",
      "        -0.02191871, -0.00890514], shape=(1536,), dtype=float32), 11: memmap([ 0.00741485, -0.02444843, -0.0131005 , ..., -0.0151765 ,\n",
      "        -0.03233534, -0.00529655], shape=(1536,), dtype=float32), 12: memmap([ 0.03158704, -0.03410709, -0.00542008, ...,  0.00104163,\n",
      "        -0.01607641, -0.02445719], shape=(1536,), dtype=float32), 13: memmap([ 0.05233577, -0.04438298,  0.00406944, ..., -0.01784779,\n",
      "        -0.0037721 , -0.01715418], shape=(1536,), dtype=float32), 14: memmap([ 0.05186514, -0.01932542,  0.00252246, ..., -0.01237501,\n",
      "        -0.01459101, -0.00421204], shape=(1536,), dtype=float32), 15: memmap([-0.05455289,  0.05051601, -0.00688857, ...,  0.01381248,\n",
      "        -0.00321252,  0.00422581], shape=(1536,), dtype=float32), 16: memmap([ 0.03599788, -0.03590748, -0.00323645, ..., -0.0032061 ,\n",
      "         0.02082119, -0.01474718], shape=(1536,), dtype=float32), 17: memmap([-0.04262666, -0.00711582, -0.00625307, ...,  0.01175671,\n",
      "        -0.01215544,  0.03723372], shape=(1536,), dtype=float32), 18: memmap([-0.04585816,  0.00306178, -0.01297659, ..., -0.00305792,\n",
      "        -0.00994309,  0.04413055], shape=(1536,), dtype=float32), 19: memmap([-0.039946  , -0.02314533, -0.02098039, ..., -0.01522634,\n",
      "         0.00448464,  0.01194225], shape=(1536,), dtype=float32), 20: memmap([-0.04821034, -0.02140527, -0.01080096, ..., -0.00519562,\n",
      "         0.01915157, -0.01485435], shape=(1536,), dtype=float32), 21: memmap([-0.02767595, -0.02185604, -0.00863156, ...,  0.00671491,\n",
      "         0.0142521 , -0.01549987], shape=(1536,), dtype=float32), 22: memmap([-0.01308985, -0.03384792,  0.01180688, ...,  0.00963803,\n",
      "         0.02282149, -0.01995391], shape=(1536,), dtype=float32), 23: memmap([ 0.00880783,  0.01804949, -0.00596701, ..., -0.01492349,\n",
      "        -0.02796902,  0.02025161], shape=(1536,), dtype=float32), 24: memmap([ 0.0092469 ,  0.01851668, -0.01697692, ..., -0.02800106,\n",
      "        -0.00917359,  0.04203068], shape=(1536,), dtype=float32), 25: memmap([ 0.01184213,  0.0294338 , -0.02009223, ..., -0.04346138,\n",
      "        -0.00065824,  0.03649483], shape=(1536,), dtype=float32), 26: memmap([-0.02504126, -0.01971232,  0.0092842 , ...,  0.04440765,\n",
      "        -0.01844113, -0.03817479], shape=(1536,), dtype=float32), 27: memmap([-0.01583244, -0.01718741,  0.02761258, ...,  0.04307923,\n",
      "        -0.01892481, -0.05508045], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    }
   ],
   "source": [
    "control_vector.export_gguf(vector_path)\n",
    "control_vector = StatisticalControlVector.import_gguf(vector_path)\n",
    "print(control_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
