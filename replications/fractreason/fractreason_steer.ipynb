{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meixinyu/anaconda3/envs/easysteer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:42:15 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from vllm.steer_vectors.request import SteerVectorRequest\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "from easysteer.steer import StatisticalControlVector\n",
    "from transformers import AutoTokenizer\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='pca', directions={0: memmap([-0.01747144, -0.06540639,  0.03629721, ..., -0.01541545,\n",
      "        -0.02380189, -0.01436467], shape=(1536,), dtype=float32), 1: memmap([ 0.00541517, -0.00878717,  0.00869997, ..., -0.02287901,\n",
      "        -0.02009154, -0.0380066 ], shape=(1536,), dtype=float32), 2: memmap([ 0.0027614 , -0.02800751,  0.02129964, ...,  0.06221821,\n",
      "        -0.00991458, -0.04693417], shape=(1536,), dtype=float32), 3: memmap([-0.0152957 , -0.00920365,  0.05090223, ...,  0.01643756,\n",
      "        -0.01623485, -0.03401608], shape=(1536,), dtype=float32), 4: memmap([-0.00275314,  0.00519124,  0.0310943 , ...,  0.0205216 ,\n",
      "        -0.02483266, -0.01082839], shape=(1536,), dtype=float32), 5: memmap([-0.00594618,  0.0570037 ,  0.0120637 , ..., -0.00586054,\n",
      "        -0.03283538, -0.02633283], shape=(1536,), dtype=float32), 6: memmap([-0.00142239, -0.01229366, -0.04342571, ...,  0.01767888,\n",
      "        -0.03308094, -0.02300258], shape=(1536,), dtype=float32), 7: memmap([-0.02040589,  0.00663961, -0.0282718 , ..., -0.02468671,\n",
      "        -0.01840399,  0.01742752], shape=(1536,), dtype=float32), 8: memmap([ 0.01465865, -0.00361927,  0.00934691, ..., -0.01005435,\n",
      "        -0.0011407 ,  0.02067084], shape=(1536,), dtype=float32), 9: memmap([-0.01085137, -0.02380315, -0.00677232, ..., -0.03019802,\n",
      "        -0.022454  ,  0.02122905], shape=(1536,), dtype=float32), 10: memmap([-0.01485075, -0.00740838, -0.01731048, ...,  0.03283988,\n",
      "         0.00287989,  0.01551536], shape=(1536,), dtype=float32), 11: memmap([-9.5934812e-03, -1.8852908e-02, -7.6041603e-03, ...,\n",
      "        -1.7693628e-03, -2.2589948e-02,  3.8045691e-05],\n",
      "       shape=(1536,), dtype=float32), 12: memmap([ 0.00559816, -0.01702257,  0.02448497, ...,  0.00675118,\n",
      "        -0.00803517,  0.00506545], shape=(1536,), dtype=float32), 13: memmap([ 0.00572556, -0.00974729,  0.03076053, ..., -0.01507609,\n",
      "        -0.01350102, -0.00411729], shape=(1536,), dtype=float32), 14: memmap([-1.9190103e-02, -4.2246161e-03, -8.5388804e-03, ...,\n",
      "        -2.7724203e-02, -7.3988180e-05,  9.1420300e-03],\n",
      "       shape=(1536,), dtype=float32), 15: memmap([ 0.01866284, -0.02272354, -0.00202954, ..., -0.03342488,\n",
      "         0.02802262, -0.0026282 ], shape=(1536,), dtype=float32), 16: memmap([-0.00035925,  0.00674251,  0.04291813, ...,  0.01609363,\n",
      "        -0.01590933,  0.0267297 ], shape=(1536,), dtype=float32), 17: memmap([ 0.00024353,  0.01548512,  0.03870299, ...,  0.03860233,\n",
      "        -0.02716066,  0.0206278 ], shape=(1536,), dtype=float32), 18: memmap([-0.01393995,  0.02529683,  0.03707359, ...,  0.05461857,\n",
      "        -0.02045523,  0.00573174], shape=(1536,), dtype=float32), 19: memmap([ 0.00802274, -0.00880536,  0.0068681 , ...,  0.02483029,\n",
      "        -0.03086064, -0.01723864], shape=(1536,), dtype=float32), 20: memmap([-0.00954903, -0.00340702,  0.0083466 , ...,  0.03393073,\n",
      "        -0.00010338, -0.01393332], shape=(1536,), dtype=float32), 21: memmap([ 0.00905891, -0.00481812,  0.01165645, ...,  0.02208113,\n",
      "        -0.00129074, -0.00790964], shape=(1536,), dtype=float32), 22: memmap([-0.00558698, -0.02364073,  0.03111887, ...,  0.03524594,\n",
      "         0.01179453, -0.00057843], shape=(1536,), dtype=float32), 23: memmap([-0.0082387 ,  0.00567672,  0.02249406, ...,  0.04076138,\n",
      "         0.01291081,  0.01699653], shape=(1536,), dtype=float32), 24: memmap([-0.00868693, -0.00457227,  0.01469296, ...,  0.05216148,\n",
      "        -0.00190352, -0.01133704], shape=(1536,), dtype=float32), 25: memmap([ 0.02076078,  0.00117271, -0.00032877, ..., -0.05764692,\n",
      "        -0.01400802, -0.01029796], shape=(1536,), dtype=float32), 26: memmap([-0.02149194, -0.00362222,  0.00619822, ...,  0.05916516,\n",
      "        -0.01171378,  0.01421941], shape=(1536,), dtype=float32), 27: memmap([ 0.01636642, -0.00615925, -0.00923991, ..., -0.05325842,\n",
      "         0.00942166,  0.00078866], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    "# vector_path=\"/home/meixinyu/EasySteer/vectors/thinking_switch_pca_MATH-500.gguf\" #change to your path\n",
    "vector_path=\"MATH500.gguf\" #change to your path\n",
    "\n",
    "control_vector = StatisticalControlVector.import_gguf(vector_path)\n",
    "print(control_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_vector_request_pos = SteerVectorRequest(\n",
    "            steer_vector_name=\"thinking_switch_pos\",\n",
    "            steer_vector_id=1,\n",
    "            steer_vector_local_path=vector_path,\n",
    "            scale=1.0,\n",
    "            prefill_trigger_tokens=\"-1\",\n",
    "            prefill_trigger_positions=[-1],\n",
    "            generate_trigger_tokens=\"-1\",\n",
    "            debug=False,\n",
    "            algorithm='direct'\n",
    "        )\n",
    "steer_vector_request_neg = SteerVectorRequest(\n",
    "            steer_vector_name=\"thinking_switch_neg\",\n",
    "            steer_vector_id=2,\n",
    "            steer_vector_local_path=vector_path,\n",
    "            scale=-1.0,\n",
    "            prefill_trigger_tokens=\"-1\",\n",
    "            prefill_trigger_positions=[-1],\n",
    "            generate_trigger_tokens=\"-1\",\n",
    "            debug=False,\n",
    "            algorithm='direct'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0.0,max_tokens=4096)\n",
    "prompt_template = \"<|im_start|>user\\n%s<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "prompt = \"Find the greatest common divisor of $3339$, $2961$, and $1491$.\"\n",
    "# prompt = \"Darrell and Allen's ages are in the ratio of 7:11. If their total age now is 162, calculate Allen's age 10 years from now.\"\n",
    "input = prompt_template % prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:42:25 [config.py:841] This model supports multiple tasks: {'classify', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 07-12 21:42:25 [config.py:1472] Using max model len 32768\n",
      "WARNING 07-12 21:42:25 [arg_utils.py:1770] --enable-steer-vector is not supported by the V1 Engine. Falling back to V0. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 21:42:25,378\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:42:25 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250712) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-12 21:42:26 [cuda.py:351] Using Flash Attention backend.\n",
      "INFO 07-12 21:42:26 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-12 21:42:26 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.13it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:42:28 [default_loader.py:272] Loading weights took 1.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:42:28 [model_runner.py:1255] Model loading took 2.8876 GiB and 1.184133 seconds\n",
      "INFO 07-12 21:42:30 [worker.py:295] Memory profiling takes 1.43 seconds\n",
      "INFO 07-12 21:42:30 [worker.py:295] the current vLLM instance can use total_gpu_memory (47.44GiB) x gpu_memory_utilization (0.90) = 42.69GiB\n",
      "INFO 07-12 21:42:30 [worker.py:295] model weights take 2.89GiB; non_torch_memory takes 0.08GiB; PyTorch activation peak memory takes 2.05GiB; the rest of the memory reserved for KV Cache is 37.68GiB.\n",
      "INFO 07-12 21:42:30 [executor_base.py:115] # cuda blocks: 88185, # CPU blocks: 9362\n",
      "INFO 07-12 21:42:30 [executor_base.py:120] Maximum concurrency for 32768 tokens per request: 43.06x\n",
      "INFO 07-12 21:42:34 [model_runner.py:1592] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:42:53 [model_runner.py:1755] Graph capturing finished in 19 secs, took 0.24 GiB\n",
      "INFO 07-12 21:42:53 [llm_engine.py:430] init engine (profile, create kv cache, warmup model) took 24.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 248.85it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.64s/it, est. speed input: 11.26 toks/s, output: 151.38 toks/s]\n",
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1251.28it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.60s/it, est. speed input: 6.21 toks/s, output: 85.29 toks/s]\n",
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1347.78it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.44s/it, est. speed input: 6.37 toks/s, output: 85.60 toks/s]\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_path, enable_steer_vector=True, tensor_parallel_size=1)\n",
    "output_base = llm.generate(\n",
    "    input,\n",
    "    sampling_params\n",
    ")\n",
    "generated_text_base = output_base[0].outputs[0].text\n",
    "\n",
    "output_pos = llm.generate(\n",
    "                input,\n",
    "                sampling_params,\n",
    "                steer_vector_request=steer_vector_request_pos\n",
    "            )\n",
    "generated_text_pos = output_pos[0].outputs[0].text\n",
    "\n",
    "output_neg = llm.generate(\n",
    "                input,\n",
    "                sampling_params,\n",
    "                steer_vector_request=steer_vector_request_neg\n",
    "            )\n",
    "generated_text_neg = output_neg[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the constant term in the expansion of \\(\\left(10x^3 - \\frac{1}{2x^2}\\right)^5\\), we use the Binomial Theorem. The Binomial Theorem states that:\n",
      "\n",
      "\\[\n",
      "(a + b)^n = \\sum_{k=0}^{n} \\binom{n}{k} a^{n-k} b^k\n",
      "\\]\n",
      "\n",
      "In our case, \\(a = 10x^3\\), \\(b = -\\frac{1}{2x^2}\\), and \\(n = 5\\). We need to find the term in the expansion where the power of \\(x\\) is zero (the constant term).\n",
      "\n",
      "The general term in the expansion is given by:\n",
      "\n",
      "\\[\n",
      "\\binom{5}{k} (10x^3)^{5-k} \\left(-\\frac{1}{2x^2}\\right)^k\n",
      "\\]\n",
      "\n",
      "Simplifying the general term, we get:\n",
      "\n",
      "\\[\n",
      "\\binom{5}{k} 10^{5-k} x^{3(5-k)} \\left(-\\frac{1}{2}\\right)^k x^{-2k} = \\binom{5}{k} 10^{5-k} \\left(-\\frac{1}{2}\\right)^k x^{15-3k-2k} = \\binom{5}{k} 10^{5-k} \\left(-\\frac{1}{2}\\right)^k x^{15-5k}\n",
      "\\]\n",
      "\n",
      "We need the exponent of \\(x\\) to be zero for the term to be constant. Therefore, we set the exponent equal to zero:\n",
      "\n",
      "\\[\n",
      "15 - 5k = 0\n",
      "\\]\n",
      "\n",
      "Solving for \\(k\\), we get:\n",
      "\n",
      "\\[\n",
      "15 = 5k \\implies k = 3\n",
      "\\]\n",
      "\n",
      "Now, we substitute \\(k = 3\\) back into the general term to find the constant term:\n",
      "\n",
      "\\[\n",
      "\\binom{5}{3} 10^{5-3} \\left(-\\frac{1}{2}\\right)^3 = \\binom{5}{3} 10^2 \\left(-\\frac{1}{2}\\right)^3 = 10 \\cdot 100 \\cdot \\left(-\\frac{1}{8}\\right) = 1000 \\cdot \\left(-\\frac{1}{8}\\right) = -125\n",
      "\\]\n",
      "\n",
      "Thus, the constant term in the expansion is:\n",
      "\n",
      "\\[\n",
      "\\boxed{-125}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "print(generated_text_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the constant term in the expansion of \\(\\left(10x^3 - \\frac{1}{2x^2}\\right)^5\\), we use the Binomial Theorem. The Binomial Theorem states that:\n",
      "\n",
      "\\[\n",
      "(a + b)^n = \\sum_{k=0}^{n} \\binom{n}{k} a^{n-k} b^k\n",
      "\\]\n",
      "\n",
      "In our case, \\(a = 10x^3\\), \\(b = -\\frac{1}{2x^2}\\), and \\(n = 5\\). We need to find the term in the expansion where the power of \\(x\\) is zero (the constant term).\n",
      "\n",
      "The general term in the expansion is given by:\n",
      "\n",
      "\\[\n",
      "T_k = \\binom{5}{k} (10x^3)^{5-k} \\left(-\\frac{1}{2x^2}\\right)^k\n",
      "\\]\n",
      "\n",
      "Simplifying the general term, we get:\n",
      "\n",
      "\\[\n",
      "T_k = \\binom{5}{k} (10)^{5-k} (x^3)^{5-k} \\left(-\\frac{1}{2}\\right)^k (x^{-2})^k\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "T_k = \\binom{5}{k} (10)^{5-k} (-1)^k \\left(\\frac{1}{2}\\right)^k x^{3(5-k) - 2k}\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "T_k = \\binom{5}{k} (10)^{5-k} (-1)^k \\left(\\frac{1}{2}\\right)^k x^{15 - 5k - 2k}\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "T_k = \\binom{5}{k} (10)^{5-k} (-1)^k \\left(\\frac{1}{2}\\right)^k x^{15 - 7k}\n",
      "\\]\n",
      "\n",
      "For the term to be a constant, the exponent of \\(x\\) must be zero:\n",
      "\n",
      "\\[\n",
      "15 - 7k = 0\n",
      "\\]\n",
      "\n",
      "Solving for \\(k\\):\n",
      "\n",
      "\\[\n",
      "15 = 7k\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "k = \\frac{15}{7}\n",
      "\\]\n",
      "\n",
      "Since \\(k\\) must be an integer, there is no integer solution for \\(k\\) that satisfies \\(15 - 7k = 0\\). Therefore, there is no constant term in the expansion of \\(\\left(10x^3 - \\frac{1}{2x^2}\\right)^5\\).\n",
      "\n",
      "Thus, the constant term is:\n",
      "\n",
      "\\[\n",
      "\\boxed{0}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "print(generated_text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the constant term in the expansion of \\(\\left(10x^3 - \\frac{1}{2x^2}\\right)^5\\), we use the Binomial Theorem. The Binomial Theorem states that:\n",
      "\n",
      "\\[\n",
      "(a + b)^n = \\sum_{k=0}^{n} \\binom{n}{k} a^{n-k} b^k\n",
      "\\]\n",
      "\n",
      "In our case, \\(a = 10x^3\\), \\(b = -\\frac{1}{2x^2}\\), and \\(n = 5\\). We need to find the term in the expansion where the power of \\(x\\) is zero (the constant term).\n",
      "\n",
      "The general term in the expansion is given by:\n",
      "\n",
      "\\[\n",
      "\\binom{5}{k} (10x^3)^{5-k} \\left(-\\frac{1}{2x^2}\\right)^k\n",
      "\\]\n",
      "\n",
      "Simplifying the general term, we get:\n",
      "\n",
      "\\[\n",
      "\\binom{5}{k} 10^{5-k} x^{3(5-k)} \\left(-\\frac{1}{2}\\right)^k x^{-2k} = \\binom{5}{k} 10^{5-k} \\left(-\\frac{1}{2}\\right)^k x^{15-3k-2k} = \\binom{5}{k} 10^{5-k} \\left(-\\frac{1}{2}\\right)^k x^{15-5k}\n",
      "\\]\n",
      "\n",
      "We need the exponent of \\(x\\) to be zero for the term to be constant. Therefore, we set the exponent equal to zero:\n",
      "\n",
      "\\[\n",
      "15 - 5k = 0\n",
      "\\]\n",
      "\n",
      "Solving for \\(k\\), we get:\n",
      "\n",
      "\\[\n",
      "15 = 5k \\implies k = 3\n",
      "\\]\n",
      "\n",
      "Now, we substitute \\(k = 3\\) back into the general term to find the constant term:\n",
      "\n",
      "\\[\n",
      "\\binom{5}{3} 10^{5-3} \\left(-\\frac{1}{2}\\right)^3 = \\binom{5}{3} 10^2 \\left(-\\frac{1}{2}\\right)^3 = 10 \\cdot 100 \\cdot \\left(-\\frac{1}{8}\\right) = 1000 \\cdot \\left(-\\frac{1}{8}\\right) = -125\n",
      "\\]\n",
      "\n",
      "Thus, the constant term in the expansion is:\n",
      "\n",
      "\\[\n",
      "\\boxed{-125}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "print(generated_text_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272\n",
      "1275\n",
      "1272\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename=f'fractreason_GSM8K_{timestamp}.txt'\n",
    "# filename=f'../../temp/fractreason_GSM8K_{timestamp}.txt'\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=== Base ===\\n\")\n",
    "    f.write(generated_text_base + \"\\n\\n\")\n",
    "    print(len(generated_text_base))\n",
    "\n",
    "    f.write(\"=== Positive: Slow thinking ===\\n\")\n",
    "    f.write(generated_text_pos + \"\\n\\n\")\n",
    "    print(len(generated_text_pos))\n",
    "\n",
    "    f.write(\"=== Negative: Fast thinking ===\\n\")\n",
    "    f.write(generated_text_neg + \"\\n\")\n",
    "    print(len(generated_text_neg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
