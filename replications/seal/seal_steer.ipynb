{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5715be-753b-475c-99b1-4b5ea19b7c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-03 14:51:02 [utils.py:253] non-default args: {'disable_log_stats': True, 'enforce_eager': True, 'enable_steer_vector': True, 'enable_chunked_prefill': False, 'model': '/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/'}\n",
      "INFO 11-03 14:51:02 [model.py:657] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 11-03 14:51:02 [model.py:1746] Using max model len 131072\n",
      "INFO 11-03 14:51:05 [scheduler.py:211] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 11-03 14:51:05 [vllm.py:414] Cudagraph is disabled under eager mode\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:05 [core.py:94] Initializing a V1 LLM engine (v0.1.dev10888+g9d4fd0da4.d20251031) with config: model='/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={'level': None, 'mode': 0, 'debug_dump_path': None, 'cache_dir': '', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'use_cudagraph': False, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'full_cuda_graph': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:10 [parallel_state.py:1325] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:11 [gpu_model_runner.py:2902] Starting to load model /data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:12 [cuda.py:420] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ac63a2b07044988e769853f7f4ba80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:13 [default_loader.py:314] Loading weights took 1.13 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:13 [steer_vector_model_runner_mixin.py:36] Initialized SteerVector worker manager\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:13 [steer_vector_model_runner_mixin.py:50] Wrapping model with steer vector support\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:13 [hidden_states_model_runner_mixin.py:90] Wrapped 28 decoder layers for hidden states capture\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:14 [gpu_model_runner.py:2971] Model loading took 3.3466 GiB and 1.303604 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:15 [gpu_worker.py:343] Available KV cache memory: 37.87 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:16 [kv_cache_utils.py:1247] GPU KV cache size: 1,418,176 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:16 [kv_cache_utils.py:1252] Maximum concurrency for 131,072 tokens per request: 10.82x\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:16 [core.py:238] init engine (profile, create kv cache, warmup model) took 2.12 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=747188)\u001b[0;0m INFO 11-03 14:51:17 [vllm.py:414] Cudagraph is disabled under eager mode\n",
      "INFO 11-03 14:51:17 [llm.py:346] Supported tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.steer_vectors.request import SteerVectorRequest, VectorConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/\"\n",
    ")\n",
    "\n",
    "# Initialize LLM with steering vector capability\n",
    "llm = LLM(\n",
    "    model=\"/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/\",\n",
    "    enable_steer_vector=True,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1,\n",
    "    enable_chunked_prefill=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cceb3a9a-ae04-4ba0-b706-0ed07ab9924b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd70c12f1dc45b39aa5e640b0aaba90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66cec002a07481ca014ff3c4b0c443d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Baseline=====\n",
      "\n",
      "Okay, so I need to figure out what two plus three equals. Hmm, let me think about this. I remember from school that when you add numbers together, you're basically combining quantities. So, if I have two apples and someone gives me three more apples, how many apples do I have in total?\n",
      "\n",
      "Wait, let me make sure I'm doing this right. Two plus three... I think addition is commutative, which means the order doesn't matter. So, two plus three is the same as three plus two. But in this case, I just need to add them together. \n",
      "\n",
      "Let me visualize it. If I have two objects, like two blocks, and then I add three more blocks, how many blocks do I have? I can count them one by one. Starting with two, then adding one makes three, then adding another makes four, and then adding the last one makes five. So, that should be five blocks in total.\n",
      "\n",
      "But wait, maybe I should use my fingers to count to double-check. If I hold up two fingers and then add three more, how many do I have? Two, three, four, five. Yeah, that's five. So, that seems right.\n",
      "\n",
      "Alternatively, I can think of it as a number line. Starting at two, if I jump three units to the right, I land on five. That also makes sense. So, both counting and using a number line method give me the same result.\n",
      "\n",
      "Is there another way to verify this? Maybe using objects or real-life examples. If I have two cookies and someone gives me three more, how many cookies do I have? Two, three, four, five. Yep, that's five cookies. So, that's consistent.\n",
      "\n",
      "I guess another way to think about it is by using addition tables or flashcards. If I look at a simple addition table, two plus three is indeed five. So, that's another confirmation.\n",
      "\n",
      "Wait, let me make sure I'm not confusing this with multiplication or something else. Two plus three is definitely addition, not multiplication. Multiplication would be two times three, which is six. So, that's different.\n",
      "\n",
      "Also, in terms of money, if I have two dollar bills and someone gives me three more, I would have five dollar bills in total. That's another practical example where two plus three equals five.\n",
      "\n",
      "I think I've covered multiple methods: counting, number line, real-life examples, addition tables, and practical applications. All of them lead me to the same conclusion that two plus three equals five. So, I'm pretty confident that's the correct answer.\n",
      "\n",
      "Just to recap, two plus three is five because when you combine two items with three more, you end up with a total of five items. Whether it's apples, cookies, money, or physical objects, the result remains the same. So, two plus three equals five.\n",
      "\n",
      "I don't think I made any mistakes here. All the methods I used to verify the answer gave me the same result. So, I can be sure that two plus three is indeed five.\n",
      "\n",
      "**Final Answer**\n",
      "The sum of two and three is \\boxed{5}.\n",
      "</think>\n",
      "\n",
      "To determine what two plus three equals, we can use various methods to verify the result:\n",
      "\n",
      "1. **Counting Method**: Starting with two objects, adding three more results in a total of five objects.\n",
      "2. **Number Line Method**: Starting at two, jumping three units to the right lands on five.\n",
      "3. **Practical Examples**: Having two cookies and adding three more results in five cookies.\n",
      "4. **Addition Table**: Two plus three is indeed five in a simple addition table.\n",
      "5. **Practical Applications**: Two dollar bills plus three more result in five dollar bills.\n",
      "\n",
      "All methods confirm that two plus three equals five.\n",
      "\n",
      "### Final Answer\n",
      "The sum of two and three is \\boxed{5}.\n",
      "Length:  793\n"
     ]
    }
   ],
   "source": [
    "# Create a simple example prompt for testing\n",
    "example = \"Please reason step by step, and put your final answer within \\\\boxed{}.\\nUser: \" + \"What does two plus three equal?\" + \"\\nAssistant: <think>\"\n",
    "# Generate baseline response without steering\n",
    "example_answers = llm.generate(\n",
    "    example,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Display baseline response\n",
    "print(\"=====Baseline=====\")\n",
    "print(example_answers[0].outputs[0].text)\n",
    "print(\"Length: \", len(tokenizer.tokenize(example_answers[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ef4e66-7a57-4041-a149-d2009f7fc0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2168e5977ab24f2ba28babe637f409c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72639294d1c49beb6e814d5b07085e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Seal=====\n",
      "\n",
      "Okay, so I need to figure out what two plus three equals. Hmm, let me think about this. I remember from school that when you add numbers together, you're basically combining quantities. So, if I have two apples and someone gives me three more apples, how many apples do I have in total?\n",
      "\n",
      " I can visualize this. If I draw two circles representing the two apples and then draw three more circles for the three apples, I can count them all together. Let me count them: one, two, three, four, five. Wait, that doesn't seem right. Did I count correctly?\n",
      "\n",
      " I think I might have made a mistake. Let me recount. Starting from the first circle, that's one. Then the second circle is two. Now, adding the three apples: the third circle is three, the fourth is four, and the fifth is five. Hmm, that still gives me five. Maybe I was too quick to count.\n",
      "\n",
      "  Alternatively, I can use my fingers to count. If I hold up two fingers and then add three more, how many do I have? Two on the first hand, and three on the second. That's five in total. Okay, that makes sense.\n",
      "\n",
      "  Another way to think about it is using objects. If I have two blocks and I add three more blocks, how many blocks do I have? Two plus three is five blocks. Yeah, that seems consistent.\n",
      "\n",
      "  Maybe I can use my knowledge of number bonds. I know that two plus three is the same as three plus two because addition is commutative. So, if I think of three as the first number, then adding two gives me five. That still works.\n",
      "\n",
      "  I also remember that in basic arithmetic, two plus three is a fundamental fact. It's one of those simple sums that kids learn early on. So, if I recall correctly, two plus three equals five.\n",
      "\n",
      "  To double-check, I can use my fingers again. If I have two fingers on one hand and three on the other, that's five. Or, if I have two on one hand and three on the same hand, that's five as well. Either way, it adds up to five.\n",
      "\n",
      "  I guess another way to verify is by using a number line. Starting at two, if I move three units to the right, I land on five. That's another visual confirmation.\n",
      "\n",
      "  Maybe I can also think about money. If I have two dollar bills and someone gives me three more, how much money do I have? Two plus three is five dollars. That makes sense.\n",
      "\n",
      "  I think I've verified it enough times. Two plus three equals five. I don't see any reason to doubt that. It's a straightforward addition problem, and the answer is consistent across different methods of verification.\n",
      "\n",
      "  So, putting it all together, two plus three equals five. I can confidently say that's the correct answer.\n",
      "</think>\n",
      "\n",
      "  Two plus three equals five. This is a fundamental arithmetic fact that can be verified through various methods such as counting, using objects, number bonds, and even a number line. Therefore, the final answer is:\n",
      "\n",
      "  \\[\n",
      "  2 + 3 = 5\n",
      "  \\]\n",
      "Seal tokens:  656\n"
     ]
    }
   ],
   "source": [
    "# Define the suffix for newline tokens in the tokenizer\n",
    "target_suffix = \"ĊĊ\"  # \"\\n\\n\" is tokenized as \"ĊĊ\"\n",
    "\n",
    "# Get complete tokenizer vocabulary\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Find all tokens and their IDs that end with the target suffix\n",
    "# These are the newline tokens we'll apply steering to\n",
    "matching_tokens_ids = [\n",
    "    token_id\n",
    "    for token, token_id in vocab.items()\n",
    "    if isinstance(token, str) and token.endswith(target_suffix)\n",
    "]\n",
    "\n",
    "# Configure steering vector request for SEAL control\n",
    "sv_request = SteerVectorRequest(\n",
    "    # Name and ID for the steering vector\n",
    "    steer_vector_name=\"complex_control\",\n",
    "    steer_vector_int_id=1,\n",
    "    \n",
    "    # Configure the three steering vectors (execution, reflection, transition)\n",
    "    vector_configs=[\n",
    "        # Execution vector (positive scale to promote execution-like text)\n",
    "        VectorConfig(\n",
    "            path=\"execution_avg_vector.gguf\",\n",
    "            scale=1.0,                            # Positive scale promotes this behavior\n",
    "            target_layers=[20],                   # Apply at layer 20\n",
    "            generate_trigger_tokens=matching_tokens_ids,  # Apply to newline tokens\n",
    "            algorithm=\"direct\",                   # Direct application\n",
    "            normalize=False                       # Do not normalize vectors\n",
    "        ),\n",
    "        \n",
    "        # Reflection vector (negative scale to suppress reflection)\n",
    "        VectorConfig(\n",
    "            path=\"reflection_avg_vector.gguf\",\n",
    "            scale=-1.0,                           # Negative scale suppresses this behavior\n",
    "            target_layers=[20],\n",
    "            generate_trigger_tokens=matching_tokens_ids,\n",
    "            algorithm=\"direct\",\n",
    "            normalize=False\n",
    "        ),\n",
    "        \n",
    "        # Transition vector (negative scale to suppress transitions)\n",
    "        VectorConfig(\n",
    "            path=\"transition_avg_vector.gguf\",\n",
    "            scale=-1.0,                           # Negative scale suppresses this behavior\n",
    "            target_layers=[20],\n",
    "            generate_trigger_tokens=matching_tokens_ids,\n",
    "            algorithm=\"direct\", \n",
    "            normalize=False\n",
    "        ),\n",
    "    ],\n",
    "    \n",
    "    # Additional parameters\n",
    "    debug=False,                        # Don't output debug info\n",
    "    conflict_resolution=\"sequential\"    # Apply vectors in sequence\n",
    ")\n",
    "# Generate response with SEAL steering\n",
    "output = llm.generate(\n",
    "    example, \n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ), \n",
    "    steer_vector_request=sv_request\n",
    ")\n",
    "\n",
    "# Display SEAL-steered response\n",
    "print(\"=====Seal=====\")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Seal tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80adab-4355-4afc-b2fd-8fd229b5030f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
