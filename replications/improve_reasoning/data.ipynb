{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76694686-f7c6-408b-b12e-3d5a2716c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"A basketball team has 3 players. Player A scored 15 points. Player B scored twice as many points as Player A. Player C scored 10 points less than Player B. What is the total score of the team?\",\n",
    "    \"A recipe for 12 cookies requires 2 cups of flour. If you want to bake 36 cookies, how many cups of flour do you need?\",\n",
    "    \"A book has 300 pages. A student reads 25 pages per day for a full week. How many pages are left to read?\",\n",
    "    \"Sarah starts with $50 in her savings account. She saves an additional $10 every week for 8 weeks. Then she spends $20 on a toy. How much money does she have left?\",\n",
    "    \"A jacket costs $80. It is on sale with a 25% discount. What is the final price of the jacket?\",\n",
    "    \"A train travels at a constant speed of 60 miles per hour. How long will it take to travel a distance of 150 miles?\",\n",
    "    \"A farmer has 4 fields. Each field contains 120 apple trees, and each tree produces 10 apples. How many apples does the farmer have in total?\",\n",
    "    \"The temperature in the morning was 15 degrees Celsius. It dropped by 2 degrees every hour for 6 hours. What is the new temperature?\",\n",
    "    \"A large box contains 144 pencils. A teacher buys 3 boxes and wants to distribute all the pencils equally among her 24 students. How many pencils does each student get?\",\n",
    "    \"For a party of 30 people, the host estimates they will need 2 pizzas for every 5 people. How many pizzas should the host order?\"\n",
    "]\n",
    "\n",
    "positive_answers = [\n",
    "    \"Player A scored 15 points. Player B scored 15 * 2 = 30 points. Player C scored 30 - 10 = 20 points. The total score is 15 + 30 + 20 = 65 points. #### 65\",\n",
    "    \"To make 36 cookies, you need to make 36 / 12 = 3 batches. Each batch needs 2 cups of flour. So, you need 3 * 2 = 6 cups of flour. #### 6\",\n",
    "    \"In a week (7 days), the student reads 25 * 7 = 175 pages. The number of pages left is 300 - 175 = 125 pages. #### 125\",\n",
    "    \"Over 8 weeks, Sarah saves 10 * 8 = $80. Her total money becomes 50 + 80 = $130. After spending $20, she has 130 - 20 = $110 left. #### 110\",\n",
    "    \"The discount amount is 25% of $80, which is 80 * 0.25 = $20. The final price is the original price minus the discount, so 80 - 20 = $60. #### 60\",\n",
    "    \"Time is calculated as Distance / Speed. So, the time it will take is 150 miles / 60 mph = 2.5 hours. #### 2.5\",\n",
    "    \"The total number of trees is 4 fields * 120 trees/field = 480 trees. The total number of apples is 480 trees * 10 apples/tree = 4800 apples. #### 4800\",\n",
    "    \"The total temperature drop over 6 hours is 2 * 6 = 12 degrees. The new temperature is 15 - 12 = 3 degrees Celsius. #### 3\",\n",
    "    \"The total number of pencils is 3 boxes * 144 pencils/box = 432 pencils. The number of pencils per student is 432 / 24 = 18 pencils. #### 18\",\n",
    "    \"The number of groups of 5 people is 30 / 5 = 6 groups. Each group needs 2 pizzas, so the total number of pizzas needed is 6 * 2 = 12 pizzas. #### 12\"\n",
    "]\n",
    "\n",
    "negative_answers = [\n",
    "    \"Player A scored 15 points. Player B scored 15 * 2 = 30 points. Player C scored 15 - 10 = 5 points. The total score is 15 + 30 + 5 = 50 points. #### 50\",\n",
    "    \"You want to make 36 cookies, which is 24 more than 12. So you need 2 + 24 = 26 cups of flour. #### 26\",\n",
    "    \"In a week (7 days), the student reads 25 * 7 = 175 pages. The number of pages left is 300 + 175 = 475 pages. #### 475\",\n",
    "    \"Over 8 weeks, Sarah saves 10 * 8 = $80. After spending $20, she has 80 - 20 = $60 left. #### 60\",\n",
    "    \"The discount is 25%. The final price is 80 * 0.25 = $20. #### 20\",\n",
    "    \"Time is calculated as Speed / Distance. So, the time it will take is 60 mph / 150 miles = 0.4 hours. #### 0.4\",\n",
    "    \"The farmer has 4 fields, 120 trees, and 10 apples. The total number of apples is 4 + 120 + 10 = 134 apples. #### 134\",\n",
    "    \"The total temperature drop over 6 hours is 2 * 6 = 12 degrees. The new temperature is 15 + 12 = 27 degrees Celsius. #### 27\",\n",
    "    \"A large box contains 144 pencils. The number of pencils per student is 144 / 24 = 6 pencils. #### 6\",\n",
    "    \"The number of groups of 5 people is 30 / 5 = 6 groups. The total number of pizzas is 30 + 6 + 2 = 38 pizzas. #### 38\"\n",
    "]\n",
    "\n",
    "\n",
    "formatted_positive = []\n",
    "formatted_negative = []\n",
    "for i in range(len(questions)):\n",
    "    formatted_positive.append(f\"[INST] {questions[i]} [/INST] {positive_answers[i]}\")\n",
    "    formatted_negative.append(f\"[INST] {questions[i]} [/INST] {negative_answers[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bce06f-6236-42d2-b3de-e9dbf2a27e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[INST] A basketball team has 3 players. Player A scored 15 points. Player B scored twice as many points as Player A. Player C scored 10 points less than Player B. What is the total score of the team? [/INST] Player A scored 15 points. Player B scored 15 * 2 = 30 points. Player C scored 30 - 10 = 20 points. The total score is 15 + 30 + 20 = 65 points. #### 65', '[INST] A recipe for 12 cookies requires 2 cups of flour. If you want to bake 36 cookies, how many cups of flour do you need? [/INST] To make 36 cookies, you need to make 36 / 12 = 3 batches. Each batch needs 2 cups of flour. So, you need 3 * 2 = 6 cups of flour. #### 6', '[INST] A book has 300 pages. A student reads 25 pages per day for a full week. How many pages are left to read? [/INST] In a week (7 days), the student reads 25 * 7 = 175 pages. The number of pages left is 300 - 175 = 125 pages. #### 125', '[INST] Sarah starts with $50 in her savings account. She saves an additional $10 every week for 8 weeks. Then she spends $20 on a toy. How much money does she have left? [/INST] Over 8 weeks, Sarah saves 10 * 8 = $80. Her total money becomes 50 + 80 = $130. After spending $20, she has 130 - 20 = $110 left. #### 110', '[INST] A jacket costs $80. It is on sale with a 25% discount. What is the final price of the jacket? [/INST] The discount amount is 25% of $80, which is 80 * 0.25 = $20. The final price is the original price minus the discount, so 80 - 20 = $60. #### 60', '[INST] A train travels at a constant speed of 60 miles per hour. How long will it take to travel a distance of 150 miles? [/INST] Time is calculated as Distance / Speed. So, the time it will take is 150 miles / 60 mph = 2.5 hours. #### 2.5', '[INST] A farmer has 4 fields. Each field contains 120 apple trees, and each tree produces 10 apples. How many apples does the farmer have in total? [/INST] The total number of trees is 4 fields * 120 trees/field = 480 trees. The total number of apples is 480 trees * 10 apples/tree = 4800 apples. #### 4800', '[INST] The temperature in the morning was 15 degrees Celsius. It dropped by 2 degrees every hour for 6 hours. What is the new temperature? [/INST] The total temperature drop over 6 hours is 2 * 6 = 12 degrees. The new temperature is 15 - 12 = 3 degrees Celsius. #### 3', '[INST] A large box contains 144 pencils. A teacher buys 3 boxes and wants to distribute all the pencils equally among her 24 students. How many pencils does each student get? [/INST] The total number of pencils is 3 boxes * 144 pencils/box = 432 pencils. The number of pencils per student is 432 / 24 = 18 pencils. #### 18', '[INST] For a party of 30 people, the host estimates they will need 2 pizzas for every 5 people. How many pizzas should the host order? [/INST] The number of groups of 5 people is 30 / 5 = 6 groups. Each group needs 2 pizzas, so the total number of pizzas needed is 6 * 2 = 12 pizzas. #### 12']\n"
     ]
    }
   ],
   "source": [
    "print(formatted_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa54f0e1-5714-431a-81a8-f9d041e74f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-03 15:38:41 [utils.py:253] non-default args: {'task': 'embed', 'enable_prefix_caching': False, 'disable_log_stats': True, 'enforce_eager': True, 'enable_chunked_prefill': False, 'model': '/home/xhl/huggingface_models/mistralai/Mistral-7B-Instruct-v0.1'}\n",
      "INFO 11-03 15:38:41 [model.py:657] Resolved architecture: MistralForCausalLM\n",
      "INFO 11-03 15:38:41 [model.py:1746] Using max model len 32768\n",
      "INFO 11-03 15:38:45 [vllm.py:414] Cudagraph is disabled under eager mode\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:38:45 [core.py:94] Initializing a V1 LLM engine (v0.1.dev10888+g9d4fd0da4.d20251031) with config: model='/home/xhl/huggingface_models/mistralai/Mistral-7B-Instruct-v0.1', speculative_config=None, tokenizer='/home/xhl/huggingface_models/mistralai/Mistral-7B-Instruct-v0.1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/xhl/huggingface_models/mistralai/Mistral-7B-Instruct-v0.1, enable_prefix_caching=False, chunked_prefill_enabled=False, pooler_config=PoolerConfig(pooling_type='LAST', normalize=None, dimensions=None, enable_chunked_processing=None, max_embed_len=None, softmax=None, activation=None, use_activation=None, logit_bias=None, step_tag_id=None, returned_token_ids=None), compilation_config={'level': None, 'mode': 0, 'debug_dump_path': None, 'cache_dir': '', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'use_cudagraph': False, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'full_cuda_graph': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:38:47 [parallel_state.py:1325] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:38:48 [gpu_model_runner.py:2902] Starting to load model /home/xhl/huggingface_models/mistralai/Mistral-7B-Instruct-v0.1...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:38:49 [cuda.py:420] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f60f9a2c7bc4bdd81cb3d84f5167275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:15 [default_loader.py:314] Loading weights took 146.71 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:15 [hidden_states_model_runner_mixin.py:90] Wrapped 32 decoder layers for hidden states capture\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:16 [gpu_model_runner.py:2971] Model loading took 13.2526 GiB and 146.947298 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:22 [gpu_worker.py:343] Available KV cache memory: 25.99 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:22 [kv_cache_utils.py:1247] GPU KV cache size: 212,912 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:22 [kv_cache_utils.py:1252] Maximum concurrency for 32,768 tokens per request: 6.49x\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:22 [core.py:238] init engine (profile, create kv cache, warmup model) took 5.99 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=777433)\u001b[0;0m INFO 11-03 15:41:22 [vllm.py:414] Cudagraph is disabled under eager mode\n",
      "INFO 11-03 15:41:23 [llm.py:346] Supported tasks: ['token_embed', 'embed']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea23eff3ee04762b0f3cad95c7ca8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca0713a0ea941f1bca50b0869602abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import easysteer.hidden_states as hs\n",
    "from vllm import LLM\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "llm = LLM(\n",
    "    model=\"/home/xhl/huggingface_models/mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    task=\"embed\", \n",
    "    tensor_parallel_size=1,\n",
    "    enforce_eager=True,\n",
    "    enable_prefix_caching=False,\n",
    "    enable_chunked_prefill=False\n",
    ")\n",
    "all_hidden_states, outputs = hs.get_all_hidden_states(llm, formatted_positive+formatted_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f06d83-b369-45a7-acf5-69312844be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5586de33d943de81de627063cba019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing DiffMean directions:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easysteer.steer import extract_diffmean_control_vector, StatisticalControlVector\n",
    "control_vector = extract_diffmean_control_vector(\n",
    "    all_hidden_states=all_hidden_states, \n",
    "    positive_indices=list(range(10)),  \n",
    "    negative_indices=list(range(10,20)),  \n",
    "    model_type=\"llama\",\n",
    "    token_pos=-1,\n",
    "    normalize=True\n",
    ")\n",
    "control_vector.export_gguf(\"reason.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939fb1c2-f11f-442b-af0d-b228a9af6406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
