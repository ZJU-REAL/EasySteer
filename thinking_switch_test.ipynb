{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:05:32.388215Z",
     "start_time": "2025-07-10T08:05:22.470145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 16:10:43 [config.py:1472] Using max model len 32768\n",
      "INFO 07-10 16:10:43 [config.py:4615] Only \"last\" pooling supports chunked prefill and prefix caching; disabling both.\n",
      "INFO 07-10 16:10:43 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250710) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-10 16:10:44 [cuda.py:351] Using Flash Attention backend.\n",
      "INFO 07-10 16:10:45 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-10 16:10:45 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.44it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 16:10:47 [default_loader.py:272] Loading weights took 0.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 16:10:47 [model_runner.py:1255] Model loading took 2.8876 GiB and 0.997674 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vllm\n",
    "from hidden_states import get_all_hidden_states\n",
    "from vllm import LLM\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "model_name = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    "llm = LLM(model=model_name, task=\"reward\", tensor_parallel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 4/4 [00:00<00:00, 326.95it/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00,  4.27it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "slow_thinking=[\"Please give the detailed thinking progress.\",\"Output the complete thinking steps.\"]\n",
    "fast_thinking=[\"Output the answer directly.\",\"Just give me the answer.\"]\n",
    "texts = []\n",
    "for t in slow_thinking+fast_thinking:\n",
    "    texts.append(f\"\"\"<|im_start|>user\n",
    "{t}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "That\"\"\")\n",
    "all_hidden_states, outputs = get_all_hidden_states(llm, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steer import (extract_statistical_control_vector,\n",
    "    extract_diffmean_control_vector,\n",
    "    extract_pca_control_vector,\n",
    "    extract_lat_control_vector,\n",
    "    extract_gemmascope_sae_diffmean_control_vector,\n",
    "    extract_linear_probe_control_vector,\n",
    "    StatisticalControlVector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing DiffMean directions: 100%|██████████| 28/28 [00:00<00:00, 9812.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='diffmean', directions={0: memmap([-0.03187475,  0.01142179, -0.03160913, ..., -0.00478121,\n",
      "         0.01248428,  0.00790228], shape=(1536,), dtype=float32), 1: memmap([ 0.00872863, -0.01371641,  0.00514366, ..., -0.03647319,\n",
      "        -0.03070606, -0.00280563], shape=(1536,), dtype=float32), 2: memmap([ 0.02447614,  0.0163406 ,  0.00570183, ..., -0.03365469,\n",
      "         0.00344196,  0.01446317], shape=(1536,), dtype=float32), 3: memmap([ 0.01258381,  0.01209226, -0.0098311 , ..., -0.03342575,\n",
      "        -0.02204625, -0.00629191], shape=(1536,), dtype=float32), 4: memmap([-0.00981627,  0.02515419,  0.02270012, ..., -0.01525028,\n",
      "        -0.00219113, -0.02646887], shape=(1536,), dtype=float32), 5: memmap([-0.00832835,  0.03097105, -0.00659328, ...,  0.00589925,\n",
      "         0.01752423, -0.00416417], shape=(1536,), dtype=float32), 6: memmap([ 0.0026915 ,  0.01034547, -0.00302794, ...,  0.01000903,\n",
      "        -0.00765397, -0.0211956 ], shape=(1536,), dtype=float32), 7: memmap([ 0.00791339,  0.00713618, -0.00770142, ...,  0.00662393,\n",
      "        -0.03334928, -0.00395669], shape=(1536,), dtype=float32), 8: memmap([-0.00355907, -0.02656592, -0.00781724, ...,  0.00851635,\n",
      "        -0.0249135 ,  0.00902479], shape=(1536,), dtype=float32), 9: memmap([-0.00472333,  0.01109983,  0.00484141, ...,  0.0021255 ,\n",
      "         0.00944666,  0.02487129], shape=(1536,), dtype=float32), 10: memmap([ 0.00400541,  0.01406899,  0.00130176, ...,  0.01151554,\n",
      "         0.00921243, -0.00305412], shape=(1536,), dtype=float32), 11: memmap([ 0.00573933, -0.01522516, -0.03427655, ...,  0.00980469,\n",
      "         0.05045826,  0.02510956], shape=(1536,), dtype=float32), 12: memmap([-0.0168662 , -0.0202545 , -0.01144492, ...,  0.02168511,\n",
      "         0.05948346,  0.02778405], shape=(1536,), dtype=float32), 13: memmap([-0.00253126,  0.01493441, -0.00177188, ...,  0.0292993 ,\n",
      "         0.01971216,  0.01676958], shape=(1536,), dtype=float32), 14: memmap([ 0.00048358,  0.01994753, -0.00235744, ...,  0.02372547,\n",
      "         0.00894616,  0.02139826], shape=(1536,), dtype=float32), 15: memmap([-0.02317229,  0.01412062,  0.00170473, ...,  0.0046767 ,\n",
      "        -0.02962916,  0.00193102], shape=(1536,), dtype=float32), 16: memmap([-0.03397929,  0.0060358 ,  0.01408352, ...,  0.03333659,\n",
      "         0.00162072, -0.00447096], shape=(1536,), dtype=float32), 17: memmap([-0.04201182,  0.04660049, -0.01435234, ..., -0.00321207,\n",
      "        -0.00050985,  0.00397685], shape=(1536,), dtype=float32), 18: memmap([-0.04459921,  0.02635408, -0.02787451, ..., -0.00337873,\n",
      "         0.00582831,  0.01568997], shape=(1536,), dtype=float32), 19: memmap([-0.04327329,  0.02906523, -0.03616025, ...,  0.00548128,\n",
      "         0.01190015,  0.02412486], shape=(1536,), dtype=float32), 20: memmap([-0.0398041 ,  0.00376273, -0.02692996, ...,  0.03333594,\n",
      "         0.01100832, -0.02259194], shape=(1536,), dtype=float32), 21: memmap([-0.02578935,  0.02446349, -0.04939493, ...,  0.00280771,\n",
      "         0.01164681, -0.02610132], shape=(1536,), dtype=float32), 22: memmap([-0.02918033,  0.02531696, -0.05132457, ...,  0.01286352,\n",
      "         0.00604326, -0.01834562], shape=(1536,), dtype=float32), 23: memmap([-0.03330828,  0.0046347 , -0.04038533, ...,  0.01530796,\n",
      "         0.00938478, -0.01742338], shape=(1536,), dtype=float32), 24: memmap([-0.03571926, -0.00301371, -0.03297953, ...,  0.02184936,\n",
      "         0.02674664,  0.01363017], shape=(1536,), dtype=float32), 25: memmap([-0.03237447,  0.00352171, -0.02656285, ...,  0.02507837,\n",
      "         0.02951604,  0.02852111], shape=(1536,), dtype=float32), 26: memmap([-0.03669641,  0.00672258, -0.02069555, ...,  0.00644479,\n",
      "         0.03039051, -0.00072226], shape=(1536,), dtype=float32), 27: memmap([-0.01085069,  0.00104375, -0.02321266, ...,  0.00487085,\n",
      "         0.0250501 ,  0.00752373], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    }
   ],
   "source": [
    "control_vector = extract_diffmean_control_vector(\n",
    "    all_hidden_states=all_hidden_states,  # 三维列表 [样本][layer][token]\n",
    "    positive_indices=[0, 1],     # 正样本索引\n",
    "    negative_indices=[2, 3],     # 负样本索引\n",
    "    model_type=\"qwen2.5\",\n",
    "    token_pos=-1,      # 使用最后一个token（默认）\n",
    "    normalize=True\n",
    ")\n",
    "control_vector.export_gguf(\"thinking_switch_control_vector.gguf\")\n",
    "control_vector = StatisticalControlVector.import_gguf(\"thinking_switch_control_vector.gguf\")\n",
    "print(control_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
