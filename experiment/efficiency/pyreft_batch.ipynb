{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a14d4-6a46-4502-88be-7a0cac904860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"/home/xhl/eval/my_eval/data/math/train.jsonl\"\n",
    "\n",
    "problems = []\n",
    "answers = []\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        problems.append(item[\"problem\"])\n",
    "        answers.append(item[\"answer\"])\n",
    "examples = [\"Please reason step by step, and put your final answer within \\\\boxed{}.\\nUser: \" + prompt + \"\\nAssistant: <think>\" for prompt in problems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdef79-98b6-4487-b063-952613653cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import easysteer.reft.pyreft as pyreft\n",
    "import os\n",
    "import time\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model_name_or_path = \"/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/\"\n",
    "reft_save_dir = \"./speed_test\" \n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=torch.bfloat16, device_map=device\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path, padding_side=\"left\", use_fast=False\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "reft_model = pyreft.ReftModel.load(reft_save_dir, model)\n",
    "reft_model.set_device(device)\n",
    "reft_model.eval()\n",
    "\n",
    "# 关键：改为左填充，让所有样本的提示末位对齐到同一列\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "\n",
    "# 1) 左填充的批量编码\n",
    "batch_size = 256\n",
    "batch = tokenizer(\n",
    "    examples[:batch_size],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ").to(device)\n",
    "\n",
    "input_dict = {\n",
    "    \"input_ids\": batch[\"input_ids\"],\n",
    "    \"attention_mask\": batch[\"attention_mask\"],\n",
    "}\n",
    "\n",
    "# 2) 干预所有提示位置：用整个序列长度的索引范围\n",
    "seq_len = input_dict[\"input_ids\"].shape[1]\n",
    "all_pos = list(range(seq_len))            # [0, 1, 2, ..., seq_len-1]\n",
    "unit_locations = {\"base\": all_pos}        # 让 ReFT 自动广播到 batch 与所有 interventions\n",
    "\n",
    "# 3) 生成\n",
    "time1 = time.time()\n",
    "_, generated = reft_model.generate(\n",
    "    input_dict,\n",
    "    # unit_locations=unit_locations,\n",
    "    intervene_on_prompt=False,\n",
    "    max_new_tokens=2048,\n",
    "    do_sample=False,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    early_stopping=True,\n",
    ")\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99679a72-35af-4759-95de-f123c1c65aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总生成 token 数（逐样本：输出有效长度 - 输入长度）\n",
    "input_lens = input_dict[\"attention_mask\"].sum(dim=1).to(generated.device)\n",
    "if tokenizer.pad_token_id is not None:\n",
    "    out_valid_lens = (generated != tokenizer.pad_token_id).sum(dim=1) \n",
    "else:\n",
    "    out_valid_lens = torch.full((generated.size(0),), generated.size(1), device=generated.device)\n",
    "new_tokens_per_seq = (out_valid_lens - input_lens).clamp(min=0)\n",
    "total_new_tokens = int(new_tokens_per_seq.sum().item())\n",
    "tok_per_s = total_new_tokens / (time2 - time1)\n",
    "req_per_s = (time2 - time1) / batch_size\n",
    "print(f\"{(time2 - time1)/batch_size:.8f}s/req\")\n",
    "print(f\"throughput: {tok_per_s:.2f} tok/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913ede5-7f52-499c-976d-9962e01e1461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
