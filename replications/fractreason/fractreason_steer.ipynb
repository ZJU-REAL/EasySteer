{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-04 00:33:18 [utils.py:253] non-default args: {'disable_log_stats': True, 'enforce_eager': True, 'enable_steer_vector': True, 'enable_chunked_prefill': False, 'model': '/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/'}\n",
      "INFO 11-04 00:33:18 [model.py:657] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 11-04 00:33:18 [model.py:1746] Using max model len 32768\n",
      "INFO 11-04 00:33:20 [scheduler.py:211] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 11-04 00:33:20 [vllm.py:414] Cudagraph is disabled under eager mode\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:21 [core.py:94] Initializing a V1 LLM engine (v0.1.dev10888+g9d4fd0da4.d20251031) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={'level': None, 'mode': 0, 'debug_dump_path': None, 'cache_dir': '', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'use_cudagraph': False, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'full_cuda_graph': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:23 [parallel_state.py:1325] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:23 [gpu_model_runner.py:2902] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:24 [cuda.py:420] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81f639ce4b044aabc63f6b90812088f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:25 [default_loader.py:314] Loading weights took 0.84 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:25 [steer_vector_model_runner_mixin.py:36] Initialized SteerVector worker manager\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:25 [steer_vector_model_runner_mixin.py:50] Wrapping model with steer vector support\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:25 [hidden_states_model_runner_mixin.py:90] Wrapped 28 decoder layers for hidden states capture\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:26 [gpu_model_runner.py:2971] Model loading took 2.8876 GiB and 0.996471 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:27 [gpu_worker.py:343] Available KV cache memory: 38.36 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:28 [kv_cache_utils.py:1247] GPU KV cache size: 1,436,560 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:28 [kv_cache_utils.py:1252] Maximum concurrency for 32,768 tokens per request: 43.84x\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:28 [core.py:238] init engine (profile, create kv cache, warmup model) took 2.03 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2691009)\u001b[0;0m INFO 11-04 00:33:28 [vllm.py:414] Cudagraph is disabled under eager mode\n",
      "INFO 11-04 00:33:29 [llm.py:346] Supported tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vllm.steer_vectors.request import SteerVectorRequest\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "llm = LLM(\n",
    "    model=\"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\",\n",
    "    enable_steer_vector=True,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1,\n",
    "    enable_chunked_prefill=False\n",
    ")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13a35b1f7654868b5188dec62effc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aad9c76aef4564bf5a79412423ee67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the greatest common divisor (GCD) of the numbers 3339, 2961, and 1491, we will use the Euclidean algorithm. The Euclidean algorithm involves repeated division and taking remainders until we reach a remainder of 0. The last non-zero remainder is the GCD.\n",
      "\n",
      "First, we find the GCD of 3339 and 2961.\n",
      "\n",
      "1. Divide 3339 by 2961 and find the remainder:\n",
      "   \\[\n",
      "   3339 = 2961 \\cdot 1 + 378\n",
      "   \\]\n",
      "   So, the remainder is 378.\n",
      "\n",
      "2. Now, we need to find the GCD of 2961 and 378. Divide 2961 by 378:\n",
      "   \\[\n",
      "   2961 = 378 \\cdot 7 + 255\n",
      "   \\]\n",
      "   So, the remainder is 255.\n",
      "\n",
      "3. Next, we find the GCD of 378 and 255. Divide 378 by 255:\n",
      "   \\[\n",
      "   378 = 255 \\cdot 1 + 123\n",
      "   \\]\n",
      "   So, the remainder is 123.\n",
      "\n",
      "4. Now, we find the GCD of 255 and 123. Divide 255 by 123:\n",
      "   \\[\n",
      "   255 = 123 \\cdot 2 + 0\n",
      "   \\]\n",
      "   So, the remainder is 0. The last non-zero remainder is 123.\n",
      "\n",
      "Thus, the GCD of 3339 and 2961 is 123.\n",
      "\n",
      "Next, we need to find the GCD of 123 and 1491.\n",
      "\n",
      "1. Divide 1491 by 123:\n",
      "   \\[\n",
      "   1491 = 123 \\cdot 12 + 15\n",
      "   \\]\n",
      "   So, the remainder is 15.\n",
      "\n",
      "2. Now, we find the GCD of 123 and 15. Divide 123 by 15:\n",
      "   \\[\n",
      "   123 = 15 \\cdot 8 + 3\n",
      "   \\]\n",
      "   So, the remainder is 3.\n",
      "\n",
      "3. Next, we find the GCD of 15 and 3. Divide 15 by 3:\n",
      "   \\[\n",
      "   15 = 3 \\cdot 5 + 0\n",
      "   \\]\n",
      "   So, the remainder is 0. The last non-zero remainder is 3.\n",
      "\n",
      "Thus, the GCD of 123 and 1491 is 3.\n",
      "\n",
      "Therefore, the greatest common divisor of 3339, 2961, and 1491 is \\(\\boxed{3}\\).\n",
      "Baseline tokens:  637\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"<|im_start|>user\\n%s<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "prompt = \"Find the greatest common divisor of $3339$, $2961$, and $1491$.\"\n",
    "text = prompt_template % prompt\n",
    "\n",
    "output = llm.generate(\n",
    "    text,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    ")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Baseline tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d068cc71a0407eb7676572f8008b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9353acb1b5a544ef824a2d961e9a8d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the greatest common divisor (GCD) of the numbers 3339, 2961, and 1491, we will use the Euclidean algorithm. The Euclidean algorithm is a method for finding the GCD of two numbers by repeatedly applying the division algorithm. We will extend this method to three numbers by breaking it down into steps.\n",
      "\n",
      "### Step 1: GCD of 3339 and 2961\n",
      "First, we find the GCD of 3339 and 2961.\n",
      "\n",
      "1. **Step 1.1: Divide 3339 by 2961 and find the remainder.**\n",
      "   \\[\n",
      "   3339 \\div 2961 \\approx 1.123 \\quad \\text{(not an integer, so we need to adjust our approach)}\n",
      "   \\]\n",
      "   Let's try a different approach by using the Euclidean algorithm directly.\n",
      "\n",
      "2. **Step 1.2: Use the Euclidean algorithm for 3339 and 2961.**\n",
      "   \\[\n",
      "   \\begin{align*}\n",
      "   3339 &= 2961 \\times 1 + 378 \\\\\n",
      "   2961 &= 378 \\times 7 + 375 \\\\\n",
      "   378 &= 375 \\times 1 + 3 \\\\\n",
      "   375 &= 375 \\times 1 + 0\n",
      "   \\end{align*}\n",
      "   \\]\n",
      "   The Euclidean algorithm shows that the GCD of 3339 and 2961 is 3.\n",
      "\n",
      "### Step 2: GCD of 3339 and 375\n",
      "Now, we need to find the GCD of 3339 and 375.\n",
      "\n",
      "1. **Step 2.1: Divide 3339 by 375 and find the remainder.**\n",
      "   \\[\n",
      "   3339 \\div 375 \\approx 8.833 \\quad \\text{(not an integer, so we need to adjust our approach)}\n",
      "   \\]\n",
      "   Let's try a different approach by using the Euclidean algorithm directly.\n",
      "\n",
      "2. **Step 2.2: Use the Euclidean algorithm for 3339 and 375.**\n",
      "   \\[\n",
      "   \\begin{align*}\n",
      "   3339 &= 375 \\times 8 + 289 \\\\\n",
      "   375 &= 289 \\times 1 + 86 \\\\\n",
      "   289 &= 86 \\times 3 + 25 \\\\\n",
      "   86 &= 25 \\times 3 + 11 \\\\\n",
      "   25 &= 11 \\times 2 + 3 \\\\\n",
      "   11 &= 3 \\times 3 + 2 \\\\\n",
      "   3 &= 2 \\times 1 + 1 \\\\\n",
      "   2 &= 1 \\times 2 + 0\n",
      "   \\end{align*}\n",
      "   \\]\n",
      "   The Euclidean algorithm shows that the GCD of 3339 and 375 is 1.\n",
      "\n",
      "### Step 3: GCD of 1 and 1491\n",
      "Now, we need to find the GCD of 1 and 1491.\n",
      "\n",
      "1. **Step 3.1: Divide 1 by 1491 and find the remainder.**\n",
      "   \\[\n",
      "   1 \\div 1491 \\approx 0.00066 \\quad \\text{(not an integer, so we need to adjust our approach)}\n",
      "   \\]\n",
      "   Let's try a different approach by using the Euclidean algorithm directly.\n",
      "\n",
      "2. **Step 3.2: Use the Euclidean algorithm for 1 and 1491.**\n",
      "   \\[\n",
      "   \\begin{align*}\n",
      "   1491 &= 1 \\times 1491 + 0\n",
      "   \\end{align*}\n",
      "   \\]\n",
      "   The Euclidean algorithm shows that the GCD of 1 and 1491 is 1.\n",
      "\n",
      "### Conclusion\n",
      "Since the GCD of 1 and any number is 1, the GCD of 3339, 2961, and 1491 is 1.\n",
      "\n",
      "\\[\n",
      "\\boxed{1}\n",
      "\\]\n",
      "Slow tokens:  944\n"
     ]
    }
   ],
   "source": [
    "steer_vector_request_pos = SteerVectorRequest(\n",
    "    steer_vector_name=\"thinking_switch_pos\",\n",
    "    steer_vector_int_id=1,\n",
    "    steer_vector_local_path=\"MATH500.gguf\",\n",
    "    scale=2.0,\n",
    "    prefill_trigger_tokens=[-1],\n",
    "    generate_trigger_tokens=[-1],\n",
    "    debug=False,\n",
    "    algorithm='direct',\n",
    "    target_layers=list(range(28))\n",
    ")\n",
    "output = llm.generate(\n",
    "    text,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    "    steer_vector_request=steer_vector_request_pos\n",
    ")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Slow tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cac1ca22b2143b2901d353ef5e1fdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cfa072648741a5b443a937f4796d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the greatest common divisor (GCD) of \\(3339\\), \\(2961\\), and \\(1491\\), we start by determining the prime factorization of each number.\n",
      "\n",
      "First, we factorize \\(3339\\):\n",
      "\\[3339 = 3 \\times 1113 = 3 \\times 3 \\times 371 = 3 \\times 3 \\times 7 \\times 53 = 3^2 \\times 7 \\times 53.\\]\n",
      "\n",
      "Next, we factorize \\(2961\\):\n",
      "\\[2961 = 3 \\times 987 = 3 \\times 3 \\times 329 = 3^2 \\times 7 \\times 53.\\]\n",
      "\n",
      "Finally, we factorize \\(1491\\):\n",
      "\\[1491 = 3 \\times 497 = 3 \\times 7 \\times 71 = 3 \\times 7^2 \\times 71.\\]\n",
      "\n",
      "The common factors of \\(3339\\), \\(2961\\), and \\(1491\\) are \\(3\\) and \\(7\\). Therefore, the GCD is:\n",
      "\\[3 \\times 7 = 21.\\]\n",
      "\n",
      "Thus, the greatest common divisor of \\(3339\\), \\(2961\\), and \\(1491\\) is \\(\\boxed{21}\\).\n",
      "Fast tokens:  316\n"
     ]
    }
   ],
   "source": [
    "steer_vector_request_neg = SteerVectorRequest(\n",
    "    steer_vector_name=\"thinking_switch_neg\",\n",
    "    steer_vector_int_id=2,\n",
    "    steer_vector_local_path=\"MATH500.gguf\",\n",
    "    scale=-2.0,\n",
    "    prefill_trigger_tokens=[-1],\n",
    "    generate_trigger_tokens=[-1],\n",
    "    debug=False,\n",
    "    algorithm='direct',\n",
    "    target_layers=list(range(28))\n",
    ")\n",
    "output = llm.generate(\n",
    "    text,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    "    steer_vector_request=steer_vector_request_neg\n",
    ")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Fast tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
