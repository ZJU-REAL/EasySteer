{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:05:32.388215Z",
     "start_time": "2025-07-10T08:05:22.470145Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import vllm\n",
    "from hidden_states import get_all_hidden_states\n",
    "from vllm import LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "model_name = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 20:40:04 [config.py:1472] Using max model len 32768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 20:40:04,572\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 20:40:04 [config.py:4615] Only \"last\" pooling supports chunked prefill and prefix caching; disabling both.\n",
      "INFO 07-10 20:40:04 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250710) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-10 20:40:05 [cuda.py:351] Using Flash Attention backend.\n",
      "INFO 07-10 20:40:06 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-10 20:40:06 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.26s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 20:40:09 [default_loader.py:272] Loading weights took 2.37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 20:40:09 [model_runner.py:1255] Model loading took 2.8876 GiB and 2.642731 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_name, task=\"reward\", tensor_parallel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 4/4 [00:00<00:00, 606.90it/s]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00,  6.86it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "slow_thinking=[\"Please give the detailed thinking progress.\",\"Output the complete thinking steps.\"]\n",
    "fast_thinking=[\"Output the answer directly.\",\"Just give me the answer.\"]\n",
    "texts = []\n",
    "for t in slow_thinking+fast_thinking:\n",
    "    texts.append(f\"\"\"<|im_start|>user\n",
    "{t}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "That\"\"\")\n",
    "all_hidden_states, outputs = get_all_hidden_states(llm, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steer import (extract_statistical_control_vector,\n",
    "    extract_diffmean_control_vector,\n",
    "    extract_pca_control_vector,\n",
    "    extract_lat_control_vector,\n",
    "    extract_gemmascope_sae_diffmean_control_vector,\n",
    "    extract_linear_probe_control_vector,\n",
    "    StatisticalControlVector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PCA directions: 100%|██████████| 28/28 [00:00<00:00, 792.55it/s]\n"
     ]
    }
   ],
   "source": [
    "control_vector = extract_pca_control_vector(\n",
    "    all_hidden_states=all_hidden_states,  # 三维列表 [样本][layer][token]\n",
    "    positive_indices=[0, 1],     # 正样本索引\n",
    "    negative_indices=[2, 3],     # 负样本索引\n",
    "    model_type=\"qwen2.5\",\n",
    "    token_pos=-1,      # 使用最后一个token（默认）\n",
    "    normalize=True\n",
    ")\n",
    "vector_name=\"temp/thinking_switch_pca_vector.gguf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='pca', directions={0: memmap([ 2.2973705e-07, -5.1668502e-04,  1.8600659e-02, ...,\n",
      "         3.5134584e-02,  4.2884856e-02,  3.7976351e-02],\n",
      "       shape=(1536,), dtype=float32), 1: memmap([-0.01999071,  0.03310987, -0.00749657, ..., -0.00187414,\n",
      "        -0.01218193, -0.01811672], shape=(1536,), dtype=float32), 2: memmap([ 0.0041185 ,  0.0122271 ,  0.01879113, ..., -0.02213749,\n",
      "        -0.02085043, -0.03191917], shape=(1536,), dtype=float32), 3: memmap([ 0.00154402, -0.01524673,  0.07874262, ..., -0.01505374,\n",
      "        -0.00781636, -0.01621172], shape=(1536,), dtype=float32), 4: memmap([ 0.01440482, -0.01530505,  0.0639211 , ..., -0.00504166,\n",
      "         0.02529835,  0.00720238], shape=(1536,), dtype=float32), 5: memmap([-0.01287344,  0.02896551, -0.0341954 , ..., -0.02252873,\n",
      "        -0.01729885, -0.01689655], shape=(1536,), dtype=float32), 6: memmap([-0.03655712, -0.00266563, -0.01523219, ..., -0.05255105,\n",
      "        -0.01028173,  0.02817955], shape=(1536,), dtype=float32), 7: memmap([ 0.00478447,  0.0470976 ,  0.0212313 , ...,  0.05236804,\n",
      "        -0.01076517, -0.05203164], shape=(1536,), dtype=float32), 8: memmap([ 0.01849671,  0.02716696,  0.01271645, ...,  0.03236914,\n",
      "        -0.01329447, -0.04017242], shape=(1536,), dtype=float32), 9: memmap([-0.00630143,  0.0299303 , -0.0294052 , ..., -0.01890334,\n",
      "         0.0112895 ,  0.04893209], shape=(1536,), dtype=float32), 10: memmap([-0.00583563,  0.01033432, -0.00145896, ..., -0.00583585,\n",
      "        -0.00291792,  0.04717312], shape=(1536,), dtype=float32), 11: memmap([-0.00298848, -0.01512794,  0.00056029, ..., -0.00896471,\n",
      "        -0.02129118,  0.02353235], shape=(1536,), dtype=float32), 12: memmap([ 0.00871774,  0.00996316,  0.02459655, ...,  0.00467023,\n",
      "        -0.00326916,  0.01977064], shape=(1536,), dtype=float32), 13: memmap([-0.00103075, -0.00824664,  0.02435334, ..., -0.01546244,\n",
      "        -0.03176243, -0.00811778], shape=(1536,), dtype=float32), 14: memmap([ 1.3939820e-07, -5.1905862e-03,  8.4936861e-03, ...,\n",
      "        -2.3888493e-02, -9.4374288e-03, -1.9818602e-02],\n",
      "       shape=(1536,), dtype=float32), 15: memmap([ 0.00921577,  0.0048382 , -0.00227511, ..., -0.0242486 ,\n",
      "         0.00138234, -0.02119593], shape=(1536,), dtype=float32), 16: memmap([ 0.0036973 ,  0.02322327,  0.00531478, ...,  0.0064124 ,\n",
      "         0.01825511, -0.00231077], shape=(1536,), dtype=float32), 17: memmap([-0.00193662, -0.0003631 , -0.01730768, ...,  0.02650617,\n",
      "        -0.00823023, -0.01851801], shape=(1536,), dtype=float32), 18: memmap([ 0.02082419, -0.02039057,  0.00954452, ...,  0.01963134,\n",
      "        -0.00130153, -0.01789597], shape=(1536,), dtype=float32), 19: memmap([ 0.0199039 , -0.00663463, -0.00953728, ..., -0.01409859,\n",
      "         0.02197721,  0.00134766], shape=(1536,), dtype=float32), 20: memmap([ 0.02513569,  0.02385921, -0.00628391, ..., -0.00785488,\n",
      "         0.03672159, -0.01767349], shape=(1536,), dtype=float32), 21: memmap([ 0.02115312,  0.01074708,  0.00409412, ..., -0.02388239,\n",
      "         0.00341177, -0.00818825], shape=(1536,), dtype=float32), 22: memmap([-0.02800204, -0.01571388, -0.00327683, ...,  0.0360451 ,\n",
      "        -0.02502305,  0.00327683], shape=(1536,), dtype=float32), 23: memmap([-0.02024159, -0.00040483, -0.01700284, ...,  0.02752841,\n",
      "        -0.03103693, -0.00512784], shape=(1536,), dtype=float32), 24: memmap([ 0.0260432 ,  0.00196552,  0.00786206, ..., -0.02162068,\n",
      "         0.0375905 ,  0.01867241], shape=(1536,), dtype=float32), 25: memmap([-0.02062686,  0.0089534 ,  0.00736672, ...,  0.02040015,\n",
      "        -0.0285602 , -0.04284031], shape=(1536,), dtype=float32), 26: memmap([ 0.01387469, -0.00610092, -0.0150555 , ..., -0.02204204,\n",
      "         0.00669133,  0.02991419], shape=(1536,), dtype=float32), 27: memmap([ 0.01497852, -0.01072327, -0.02719114, ..., -0.02859538,\n",
      "        -0.00272337,  0.02348906], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    }
   ],
   "source": [
    "control_vector.export_gguf(vector_name)\n",
    "control_vector = StatisticalControlVector.import_gguf(vector_name)\n",
    "print(control_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
