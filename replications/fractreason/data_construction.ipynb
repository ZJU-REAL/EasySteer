{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meixinyu/anaconda3/envs/easysteer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:34:40 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vllm\n",
    "import json\n",
    "from easysteer.hidden_states import get_all_hidden_states\n",
    "from vllm import LLM\n",
    "\n",
    "from easysteer.steer import extract_pca_control_vector,StatisticalControlVector\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    "\n",
    "# vector_path = \"vectors/thinking_switch_pca_MATH-500.gguf\" #MATH-500\n",
    "\n",
    "\n",
    "num_question = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../temp/test.jsonl\" #MATH-500\n",
    "# file_path = \"../../temp/test_gsm8k.jsonl\" #GSM8K\n",
    "\n",
    "vector_path = \"MATH500.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_list = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            if line_count >= num_question:\n",
    "                break\n",
    "            stripped_line = line.strip()\n",
    "            if not stripped_line:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(stripped_line)\n",
    "                if \"problem\" in data:\n",
    "                    problem_list.append(data[\"problem\"])\n",
    "                    line_count += 1\n",
    "                elif \"question\" in data:\n",
    "                    problem_list.append(data[\"question\"])\n",
    "                    line_count += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"skip: {line[:50]}...\")\n",
    "                continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"{str(e)}\")\n",
    "# problem_list = [\"Find the roots of $(x - 3)^3 + (x -7)^3 = (2x - 10)^3.$\",\"A regular hexagon can be divided into six equilateral triangles. If the perimeter of one of the triangles is 21 inches, what is the perimeter, in inches, of the regular hexagon?\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_thinking = [\n",
    "    \"Walk me through your reasoning process step by step.\"\n",
    "]\n",
    "\n",
    "fast_thinking = [\n",
    "    \"Direct answer only.\"\n",
    "]\n",
    "\n",
    "len_slow=len(slow_thinking)\n",
    "len_fast=len(fast_thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$Walk me through your reasoning process step by step.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|im_start|>user\n",
      "If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) +f(-1)+f(0)$? Express your answer as a common fraction.Walk me through your reasoning process step by step.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|im_start|>user\n",
      "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$Direct answer only.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for prob in problem_list:\n",
    "    for req in slow_thinking:\n",
    "        texts.append(f\"\"\"<|im_start|>user\n",
    "{prob}{req}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\")\n",
    "\n",
    "for prob in problem_list:\n",
    "    for req in fast_thinking:\n",
    "        texts.append(f\"\"\"<|im_start|>user\n",
    "{prob}{req}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\")\n",
    "print(texts[0])\n",
    "print(texts[num_question*len_slow-1])\n",
    "print(texts[num_question*len_slow])\n",
    "with open(\"111.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text + \"\\n\")  # 每个元素后加换行符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:34:49 [config.py:1472] Using max model len 32768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 21:34:49,720\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:34:49 [config.py:4615] Only \"last\" pooling supports chunked prefill and prefix caching; disabling both.\n",
      "INFO 07-12 21:34:49 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250712) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-12 21:34:50 [cuda.py:351] Using Flash Attention backend.\n",
      "INFO 07-12 21:34:51 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-12 21:34:51 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.12it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:34:52 [default_loader.py:272] Loading weights took 0.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 21:34:52 [model_runner.py:1255] Model loading took 2.8876 GiB and 1.140071 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 6/6 [00:00<00:00, 1173.23it/s]\n",
      "Processed prompts: 100%|██████████| 6/6 [00:00<00:00, 16.91it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_path,task=\"reward\",tensor_parallel_size=1)\n",
    "\n",
    "all_hidden_states, outputs = get_all_hidden_states(llm, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PCA directions: 100%|██████████| 28/28 [00:00<00:00, 1217.81it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "control_vector = extract_pca_control_vector(\n",
    "    all_hidden_states=all_hidden_states,\n",
    "    positive_indices=list(range(num_question*len_slow)), \n",
    "    negative_indices=list(range(num_question*len_slow,num_question*(len_slow+len_fast))),\n",
    "    model_type=\"qwen2.5\",\n",
    "    token_pos=-1,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='pca', directions={0: memmap([ 0.00726394, -0.01336981,  0.00655949, ..., -0.02067229,\n",
      "        -0.01796948,  0.0129575 ], shape=(1536,), dtype=float32), 1: memmap([ 0.01806596,  0.03636302, -0.00653954, ...,  0.01222791,\n",
      "         0.02215214, -0.02101433], shape=(1536,), dtype=float32), 2: memmap([ 0.0071452 , -0.01424347, -0.01344561, ..., -0.01061083,\n",
      "        -0.02976646, -0.0511036 ], shape=(1536,), dtype=float32), 3: memmap([-0.01978249,  0.03541886,  0.01452238, ...,  0.00620668,\n",
      "         0.02184932, -0.00258583], shape=(1536,), dtype=float32), 4: memmap([-0.02166593,  0.00685351,  0.0129449 , ..., -0.03289864,\n",
      "         0.02539678, -0.01135035], shape=(1536,), dtype=float32), 5: memmap([-0.00637604, -0.03049226, -0.0374089 , ..., -0.0454876 ,\n",
      "        -0.00044487,  0.00012361], shape=(1536,), dtype=float32), 6: memmap([ 0.01123103,  0.0168045 ,  0.04298282, ...,  0.0172068 ,\n",
      "        -0.0007676 ,  0.03093815], shape=(1536,), dtype=float32), 7: memmap([ 0.01977698,  0.04346049,  0.01998102, ..., -0.01457498,\n",
      "         0.0376961 ,  0.02008516], shape=(1536,), dtype=float32), 8: memmap([-0.01011446,  0.00537081, -0.03601602, ...,  0.04459668,\n",
      "        -0.04233025, -0.0028914 ], shape=(1536,), dtype=float32), 9: memmap([-0.00510868, -0.02058077,  0.00828479, ...,  0.00706398,\n",
      "         0.01682158, -0.00519093], shape=(1536,), dtype=float32), 10: memmap([ 0.0071756 , -0.00043693, -0.00231147, ..., -0.03304599,\n",
      "        -0.03720809, -0.0096364 ], shape=(1536,), dtype=float32), 11: memmap([ 0.00196547, -0.02725425,  0.00873551, ..., -0.02020029,\n",
      "         0.0062054 , -0.01503139], shape=(1536,), dtype=float32), 12: memmap([-0.01482222,  0.00449061,  0.00695709, ..., -0.01247195,\n",
      "         0.0112797 ,  0.01407192], shape=(1536,), dtype=float32), 13: memmap([-0.01085635,  0.00747808,  0.00089711, ...,  0.02160006,\n",
      "         0.01982038,  0.00806139], shape=(1536,), dtype=float32), 14: memmap([-0.02804754, -0.00508453,  0.01676173, ...,  0.0003745 ,\n",
      "        -0.00164141,  0.00319472], shape=(1536,), dtype=float32), 15: memmap([-0.02587485, -0.01074493,  0.00975232, ..., -0.01014797,\n",
      "        -0.02247737, -0.00380737], shape=(1536,), dtype=float32), 16: memmap([ 0.02624034, -0.00133329, -0.0421408 , ..., -0.00868801,\n",
      "         0.00353513, -0.00368111], shape=(1536,), dtype=float32), 17: memmap([-0.02666965,  0.00737043,  0.04384224, ...,  0.02589911,\n",
      "        -0.00971839,  0.02664442], shape=(1536,), dtype=float32), 18: memmap([-0.04252626,  0.01585197,  0.04402631, ...,  0.0444544 ,\n",
      "         0.01061226, -0.01030782], shape=(1536,), dtype=float32), 19: memmap([-0.02793924,  0.02733218,  0.03963078, ...,  0.02670238,\n",
      "        -0.02176381, -0.01809027], shape=(1536,), dtype=float32), 20: memmap([ 0.03771784, -0.03116493, -0.03195252, ..., -0.03269992,\n",
      "         0.01923248,  0.02600507], shape=(1536,), dtype=float32), 21: memmap([-0.01909053,  0.03385005,  0.05653341, ..., -0.00610043,\n",
      "        -0.02467347, -0.0030383 ], shape=(1536,), dtype=float32), 22: memmap([ 0.02660481, -0.02954397, -0.0737088 , ..., -0.01661371,\n",
      "        -0.01541749,  0.00271405], shape=(1536,), dtype=float32), 23: memmap([-0.01438323,  0.04956505,  0.05716783, ...,  0.02894771,\n",
      "         0.03154672,  0.00551326], shape=(1536,), dtype=float32), 24: memmap([ 0.00923675, -0.02729562, -0.04856598, ..., -0.02668311,\n",
      "        -0.02295038,  0.01386798], shape=(1536,), dtype=float32), 25: memmap([ 0.00644433, -0.03233846, -0.03626794, ..., -0.0421949 ,\n",
      "        -0.03800328, -0.00582407], shape=(1536,), dtype=float32), 26: memmap([-0.01167433,  0.03381427,  0.03123964, ...,  0.04941957,\n",
      "         0.01263774, -0.00142867], shape=(1536,), dtype=float32), 27: memmap([-0.01827507,  0.03411561,  0.0291325 , ...,  0.0452035 ,\n",
      "         0.02115851, -0.00123663], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    }
   ],
   "source": [
    "control_vector.export_gguf(vector_path)\n",
    "control_vector = StatisticalControlVector.import_gguf(vector_path)\n",
    "print(control_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
