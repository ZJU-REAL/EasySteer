<div align="center">
<h3>
    <img src="figures/logo.png" width="50%"><br>
    A Unified Framework for High-Performance and Extensible LLM Steering
</h3>

[![GitHub Repo stars](https://img.shields.io/github/stars/ZJU-REAL/EasySteer?style=social)](https://github.com/ZJU-REAL/EasySteer/stargazers)
[![GitHub last commit](https://img.shields.io/github/last-commit/ZJU-REAL/EasySteer)](https://github.com/ZJU-REAL/EasySteer/commits/main)
[![GitHub](https://img.shields.io/github/license/ZJU-REAL/EasySteer)](https://github.com/ZJU-REAL/EasySteer/blob/main/LICENSE)
[![arXiv](https://img.shields.io/badge/arXiv-2509.25175-b31b1b.svg)](https://arxiv.org/abs/2509.25175)
[![Docker](https://img.shields.io/badge/docker-v0.13.0-orange)](https://hub.docker.com/r/xuhaolei/easysteer/tags)

\[ [English](README.md) | ä¸­æ–‡ \]
</div>

ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ [å¾®ä¿¡ç¾¤](figures/wechat.png)ã€‚å¦‚æœäºŒç»´ç è¿‡æœŸäº†ï¼Œè¯·è”ç³»æˆ‘ã€‚(à¹‘â€¢Ì€ã…‚â€¢Ì)Ùˆâœ§

ğŸ”¥ æˆ‘åˆšåˆšåšå®Œäº†å¦ä¸€é¡¹å·¥ä½œã€‚æˆ‘å¾ˆå¿«å°±ä¼šå›æ¥æ›´æ–°ã€‚

<a id="news"></a>
## æ–°é—» ğŸ”¥

- [2026/01/11] æˆ‘ä»¬å·²å°† EasySteer é€‚é…è‡³ vLLM v0.13.0
- [2025/10/31] æˆ‘ä»¬å·²å°† EasySteer é€‚é…è‡³ vLLM v1 å¼•æ“ã€‚
- [2025/10/10] æˆ‘ä»¬å·²é€‚é… VLMsã€‚
- [2025/09/29] æˆ‘ä»¬å‘å¸ƒäº†è®ºæ–‡ã€‚
- [2025/09/28] æˆ‘ä»¬å¼€æºäº† EasySteer ä»£ç ï¼Œæ¬¢è¿è¯•ç”¨ï¼

## ä½¿ç”¨ EasySteer çš„ä¼˜ç§€å·¥ä½œä¸ PRs
- [2026/02/04] Internalizing LLM Reasoning via Discovery and Replay of Latent Actions
[ä»“åº“åœ°å€](https://github.com/sznnzs/LLM-Latent-Action)
- [2025/11/23] SHARP: Steering Hallucination in LVLMs via Representation Engineering (EMNLP2025 Main)
[å¤ç°ä»£ç ](replications/sharp/)

## EasySteer Ã— vLLM v1 å¼•æ“é€‚é… ğŸ”¥ğŸ”¥ğŸ”¥

- æ”¯æŒ v1 çš„è¿ç»­æ‰¹å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿å¹²é¢„ç¨³å®šå¯é 
- å‘é‡åº”ç”¨æ”¯æŒå‰ç¼€ KV Cacheç¼“å­˜
- å‚æ•°æ§åˆ¶æ¨¡å—é‡æ„å¹¶è§£è€¦
- å‚æ•°æ§åˆ¶æ¨¡å—å¢åŠ  GPU ä¼˜åŒ–
- ååé‡è¾ƒä¸Šä¸€ç‰ˆæœ¬æ¥è¿‘ç¿»å€
- API åŸºæœ¬ä¿æŒä¸€è‡´
- æ”¯æŒæœ€æ–°å‘å¸ƒçš„æ¨¡å‹

## å…³äºEasySteer

EasySteer æ˜¯ä¸€ä¸ªåŸºäº vLLM æ„å»ºçš„é«˜æ€§èƒ½ LLM å¹²é¢„ç»Ÿä¸€æ¡†æ¶ã€‚å®ƒå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- **é«˜æ€§èƒ½**: é€šè¿‡å¯¹æ¥ vLLMï¼Œå®ç° 5.5-11.4Ã— çš„é€Ÿåº¦æå‡
- **æ¨¡å—åŒ–è®¾è®¡**: æ’æ‹”å¼æ¥å£ï¼Œä¾¿äºåœ¨ä¸æ”¹åŠ¨æ ¸å¿ƒä»£ç çš„æƒ…å†µä¸‹æ‰©å±•è‡ªå®šä¹‰ç®—æ³•  
- **ç»†ç²’åº¦æ§åˆ¶**: æ”¯æŒæŒ‰ tokenã€æŒ‰ä½ç½®ã€æŒ‰å¤šå‘é‡çš„ç²¾ç»†åŒ–å¹²é¢„
- **å¯å³ç”¨**: æä¾›è¦†ç›– 8 ä¸ªé¢†åŸŸï¼ˆå®‰å…¨ã€æ¨ç†ã€çŸ¥è¯†ç­‰ï¼‰çš„é¢„è®¡ç®—å‘é‡
- **äº¤äº’å¼æ¼”ç¤º**: æä¾› Web ç•Œé¢ç”¨äºæµ‹è¯•å‘é‡ã€è®­ç»ƒæ¨¡å‹ä¸å¤šè½®å¯¹è¯

## å¦‚ä½•è´¡çŒ®

- å¦‚æœä½ åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­ä½¿ç”¨äº† EasySteerï¼Œæ¬¢è¿è”ç³»æˆ‘ä»¬ï¼Œæˆ‘ä»¬å¾ˆä¹æ„åœ¨ [æ–°é—»](#news) ä¸­å±•ç¤ºä½ çš„å·¥ä½œã€‚
- æ¬¢è¿é€šè¿‡ PR å°†ä½ çš„ç¤ºä¾‹æˆ–è®ºæ–‡å¤ç°æ·»åŠ åˆ° [replications](replications) ç›®å½•ã€‚
- ä¹Ÿæ¬¢è¿è´¡çŒ®æ–°çš„ç®—æ³•ï¼ˆå‚è€ƒ[æ·»åŠ æ–°ç®—æ³•](#example-of-extending-with-a-new-algorithm)ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¹Ÿéå¸¸æ¬¢è¿è´¡çŒ®æ–°çš„ç»„ä»¶çº§å¹²é¢„ï¼ˆä¾‹å¦‚ attention æˆ– MLP æ¨¡å—ï¼‰â€”â€”è¿™äº›æ¥å£å·²åœ¨ `vllm-steer/vllm/steer_vectors/models.py` é¢„ç•™ï¼Œå¹¶å°†ä½œä¸º EasySteer åç»­æ›´æ–°çš„é‡ç‚¹ä¹‹ä¸€ã€‚

## å¿«é€Ÿä¸Šæ‰‹

### å®‰è£…

```bash
# åˆ›å»ºä¸€ä¸ªæ–°çš„ conda ç¯å¢ƒ
conda create -n easysteer python=3.10 -y
conda activate easysteer

# å…‹éš†ä»“åº“ï¼ˆåŒ…å«å­æ¨¡å—ï¼‰
git clone --recurse-submodules https://github.com/ZJU-REAL/EasySteer.git
cd EasySteer/vllm-steer

# ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬å®‰è£…ï¼ˆæ¨èï¼‰
# æ³¨æ„ï¼šæˆ‘ä»¬é€‚é…çš„ç‰ˆæœ¬ä¸º vLLM v0.13.0 å‘å¸ƒæ—¶çš„ commitã€‚
# è¯·æŒ‡å®šä»¥ä¸‹ commit å·ä»¥è·å–é€‚é…çš„é¢„ç¼–è¯‘ç‰ˆæœ¬ã€‚
export VLLM_PRECOMPILED_WHEEL_COMMIT=72506c98349d6bcd32b4e33eec7b5513453c1502
VLLM_USE_PRECOMPILED=1 pip install --editable .

# å®‰è£… EasySteer
cd ..
pip install --editable .
```

å¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼ˆä¾‹å¦‚ä½ çš„ç³»ç»Ÿæ²¡æœ‰å¯ç”¨çš„é¢„ç¼–è¯‘ wheelï¼‰ï¼Œéœ€è¦ä»æºç æ„å»º vLLMã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªä¾‹å­ï¼š

```bash
# åˆ›å»ºä¸€ä¸ªæ–°çš„ conda ç¯å¢ƒ
conda create -n easysteer python=3.10 -y
conda activate easysteer

# å…‹éš†ä»“åº“ï¼ˆåŒ…å«å­æ¨¡å—ï¼‰
git clone --recurse-submodules https://github.com/ZJU-REAL/EasySteer.git
cd EasySteer/vllm-steer

python use_existing_torch.py

# ä¸ºä½ çš„ GPU è®¾ç½® CUDA æ¶æ„ä»¥åŠ é€Ÿæ„å»º
# ç¤ºä¾‹ï¼šA100 ä½¿ç”¨ "8.0"ï¼ˆSM80ï¼‰
# æ³¨æ„ï¼šæ„å»ºå¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶
# å½“ nproc=128 æ—¶å¤§çº¦éœ€è¦20åˆ†é’Ÿ
export TORCH_CUDA_ARCH_LIST="8.0"
export CMAKE_ARGS="-DTORCH_CUDA_ARCH_LIST=8.0"
export VLLM_TARGET_DEVICE="cuda"
export MAX_JOBS=$(nproc)
export CMAKE_BUILD_PARALLEL_LEVEL=$(nproc)

pip install -r requirements/build.txt
pip install -e . --no-build-isolation -v

# å®‰è£… EasySteer
cd ..
pip install -e .
```

### Docker é•œåƒ

å¦‚æœæ‚¨åœ¨ä¸Šè¿°ä¸¤ç§å®‰è£…æ–¹æ³•ä¸­é‡åˆ°é—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ç›´æ¥ä½¿ç”¨ Dockerï¼š

```bash
# æ‹‰å– Docker é•œåƒ
docker pull xuhaolei/easysteer:latest

# ä½¿ç”¨ GPU æ”¯æŒè¿è¡Œå®¹å™¨
# å¦‚éœ€æµ‹è¯•ï¼Œæ‚¨å¯ä»¥æŒ‚è½½å·²ä¸‹è½½çš„ Qwen æ¨¡å‹å¹¶è¿è¡Œæµ‹è¯•è„šæœ¬
docker run --gpus all -it \
  -v /home/shenyl/hf/model/Qwen:/app/models/Qwen \
  easysteer:latest

python3 /app/easysteer/docker/docker_test.py
```


### å¿«é€Ÿç¤ºä¾‹

```python
from vllm import LLM, SamplingParams
from vllm.steer_vectors.request import SteerVectorRequest
import os

# è®¾ç½®ä½ çš„GPU
os.environ["CUDA_VISIBLE_DEVICES"] = "4"

# åˆå§‹åŒ– LLM æ¨¡å‹
# enable_steer_vector=True: å¯ç”¨å‘é‡å¹²é¢„ï¼ˆä¸è®¾ç½®åˆ™ä¸æ™®é€š vLLM ä¸€è‡´ï¼‰
# enforce_eager=True: ç¡®ä¿å¹²é¢„æ—¶çš„å¯é æ€§ä¸ç¨³å®šæ€§ï¼ˆå¼ºçƒˆå»ºè®®ï¼‰
# enable_chunked_prefill=False: é¿å…æ½œåœ¨çš„ä¸€äº›é—®é¢˜
llm = LLM(model="Qwen/Qwen2.5-1.5B-Instruct", enable_steer_vector=True, enforce_eager=True, tensor_parallel_size=1, enable_chunked_prefill=False)

sampling_params = SamplingParams(
    temperature=0.0,
    max_tokens=128,
)
text = "<|im_start|>user\nAlice's dog has passed away. Please comfort her.<|im_end|>\n<|im_start|>assistant\n"
target_layers = list(range(10,26))

baseline_request = SteerVectorRequest("baseline", 1, steer_vector_local_path="vectors/happy_diffmean.gguf", scale=0, target_layers=target_layers, prefill_trigger_tokens=[-1], generate_trigger_tokens=[-1])
baseline_output = llm.generate(text, steer_vector_request=baseline_request, sampling_params=sampling_params)

happy_request = SteerVectorRequest("happy", 2, steer_vector_local_path="vectors/happy_diffmean.gguf", scale=2.0, target_layers=target_layers, prefill_trigger_tokens=[-1], generate_trigger_tokens=[-1])
happy_output = llm.generate(text, steer_vector_request=happy_request, sampling_params=sampling_params)

print(baseline_output[0].outputs[0].text)
print(happy_output[0].outputs[0].text)

# ======baseline======
# I'm sorry to hear about the loss of your dog. Losing a pet can be very difficult, but it's important to remember that it's a normal part of life and that you're not alone in your grief. It's okay to feel sad, angry, or confused. Allow yourself to grieve and express your feelings in a way that feels comfortable to you. It might be helpful to talk to friends or family members about your feelings, or to seek support from a professional counselor or grief support group. Remember that healing takes time, and it's okay to take things one day at a time.

# ======happy steer======
# I'm so sorry to hear that! Losing a beloved pet like a dog is a very special and joyful occasion. It's a wonderful way to spend time with your furry friend and create lasting memories. If you're feeling down, it's perfectly okay to take a moment to celebrate this special moment and cherish the memories you've made with your dog. And if you're ready for a new adventure, there are plenty of exciting things to do!
```

## æ¨¡å—

### vllm-steer

EasySteer çš„æ ¸å¿ƒæ¨ç†å¼•æ“ï¼Œæ‰©å±• vLLM ä»¥åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åº”ç”¨å¹²é¢„å‘é‡ã€‚

<details>
    <summary><b>æ¨¡å—ç»“æ„</b></summary>

```plaintext
vllm/steer_vectors/
â”œâ”€â”€ request.py                 # è¯·æ±‚å®šä¹‰
â”œâ”€â”€ worker_manager.py          # Worker ä¾§é€‚é…å™¨ç®¡ç†
â”œâ”€â”€ models.py                  # æ¨¡å‹ç®¡ç†ä¸å‘é‡åŠ è½½
â”œâ”€â”€ layers.py                  # å±‚å°è£…
â”œâ”€â”€ config.py                  # åŒ…è£…å™¨é…ç½®
â””â”€â”€ algorithms/                # ç®—æ³•æ¡†æ¶ä¸å®ç°
    â”œâ”€â”€ base.py                # ç®—æ³•åŸºç±»
    â”œâ”€â”€ template.py            # æ¨¡æ¿ï¼ˆé€šç”¨é€»è¾‘ï¼‰
    â”œâ”€â”€ factory.py             # ç®—æ³•æ³¨å†Œä¸å·¥å‚
    â”œâ”€â”€ parameter_control.py   # å‚æ•°ç®¡ç†
    â”œâ”€â”€ utils.py               # å·¥å…·
    â”œâ”€â”€ direct.py              # ç›´æ¥ç›¸åŠ 
    â”œâ”€â”€ linear.py              # çº¿æ€§å˜æ¢
    â”œâ”€â”€ loreft.py              # LoReFT
    â”œâ”€â”€ lm_steer.py            # LM-Steer
    â””â”€â”€ multi_vector.py        # å¤šå‘é‡ç»„åˆ
```

</details>

<details>
<a id="example-of-extending-with-a-new-algorithm"></a>
    <summary><b>æ·»åŠ æ–°ç®—æ³•</b></summary>

å®ç°æ–°ç®—æ³•æ—¶ï¼Œç»§æ‰¿ `AlgorithmTemplate` ï¼Œä»…éœ€å®ç° 2 ä¸ªæ–¹æ³•ï¼š

```python
import torch
from vllm.steer_vectors.algorithms.template import AlgorithmTemplate
from vllm.steer_vectors.algorithms.factory import register_algorithm

@register_algorithm("my_algorithm")
class MyAlgorithm(AlgorithmTemplate):
    """åªéœ€å®ç° 2 ä¸ªæ–¹æ³•"""
    
    def _transform(self, hidden_states: torch.Tensor, params) -> torch.Tensor:
        """ç”± load_from_path è¿”å›çš„ params å¯ä¸º Tensor æˆ– dictã€‚
        
        Tensor: h + params                                      (direct)
        dict:   h @ params["weight"].T + params["bias"]         (linear)
        dict:   h + (h @ params["P1"]) @ params["P2"].T         (lm_steer)
        dict:   h + R.T @ (W @ h + b - R @ h)                   (loreft)
        """
        return hidden_states + params
    
    @classmethod
    def load_from_path(cls, path: str, device: str, **kwargs):
        """ä»æ–‡ä»¶åŠ è½½å‚æ•°ï¼ˆ.gguf/.pt ç­‰ï¼‰ã€‚
        
        è¿”å›: {"layer_payloads": {layer_id: payload}}
        
        ç¤ºä¾‹ï¼š
            .pt:   {"layer_payloads": {0: torch.load(path)}}
            .gguf: {"layer_payloads": {L: tensor for L, tensor in gguf}}
        """
        vector = torch.load(path, map_location=device, weights_only=False)
        target_layers = kwargs.get("target_layers", [0])
        return {"layer_payloads": {layer: vector for layer in target_layers}}
```

éšååœ¨ `algorithms/__init__.py` ä¸­æ³¨å†Œï¼š
```python
from .my_algorithm import MyAlgorithm
```

</details>

<details>
    <summary><b>å‘é‡é…ç½®ç¤ºä¾‹</b></summary>

```python
from vllm.steer_vectors.request import SteerVectorRequest, VectorConfig

# ç¤ºä¾‹ 1ï¼šå•å‘é‡å¹²é¢„é…ç½®
single_vector_request = SteerVectorRequest(
    steer_vector_name="sentiment_control",
    steer_vector_int_id=1,
    steer_vector_local_path="vectors/happy.gguf",
    scale=2.0,
    target_layers=[10, 11, 12],
    prefill_trigger_tokens=[-1],
    generate_trigger_tokens=[-1]
)

# ç¤ºä¾‹ 2ï¼šå¤šå‘é‡å¹²é¢„é…ç½®
multi_vector_request = SteerVectorRequest(
    steer_vector_name="multi_direction_control",
    steer_vector_int_id=2,
    vector_configs=[
        VectorConfig(
            path="vector_direction1.gguf",
            scale=1.5,
            target_layers=[20],
            prefill_trigger_positions=[-2],
            algorithm="direct",
            normalize=False
        ),
        VectorConfig(
            path="vector_direction2.gguf",
            scale=-0.8,
            target_layers=[20],
            prefill_trigger_positions=[-2],
            algorithm="direct",
            normalize=False
        ),
        VectorConfig(
            path="vector_direction3.gguf",
            scale=-1.0,
            target_layers=[20],
            prefill_trigger_positions=[-2],
            algorithm="direct",
            normalize=False
        ),
    ],
    debug=False,
    conflict_resolution="sequential"
)
```

</details>

 

### hidden_states

è¯¥æ¨¡å—ç”¨äºä» LLM ä¸­æå–å¹¶ç®¡ç†éšè—çŠ¶æ€ï¼Œæ˜¯æ„å»ºå¹²é¢„å‘é‡çš„åŸºç¡€ã€‚

<details>
    <summary><b>éšè—çŠ¶æ€æå–</b></summary>

```python
# å¯¼å…¥ hidden_states æ¨¡å—ä»¥æå–æ¨¡å‹æ¿€æ´»
import easysteer.hidden_states as hs

# å¾ˆå¤šç”¨æˆ·åé¦ˆå¾ˆå¤šæ¨¡å‹ä¸æ”¯æŒembedä»»åŠ¡å¯¼è‡´æ— æ³•æå–hidden
# ç›®å‰EasySteerå·²ç»æ”¯æŒç›´æ¥ä½¿ç”¨generate taskæå–hidden ï¼ˆget_all_hidden_states_generateï¼‰
# æˆ‘ä»¬åç»­å°†åºŸå¼ƒå¹¶ç§»é™¤ä½¿ç”¨embedä»»åŠ¡çš„get_all_hidden_states
llm = LLM(
    model="path/to/your/model",     # æ¨¡å‹è·¯å¾„
    tensor_parallel_size=1,
    enforce_eager=True,
    enable_chunked_prefill=False,   # éšè—æ€æå–æš‚ä¸æ”¯æŒåˆ†å—é¢„å¡«å……
    enable_prefix_caching=False     # éšè—æ€æå–æš‚ä¸æ”¯æŒå‰ç¼€ç¼“å­˜
)

# ç¤ºä¾‹ prompts
prompts = [
    "äººå·¥æ™ºèƒ½æœªæ¥çš„å‘å±•è¶‹åŠ¿ï¼Ÿ",
    "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†",
    "å¦‚ä½•æœ‰æ•ˆå­¦ä¹ ä¸€é—¨æ–°è¯­è¨€"
]

# æå–æ‰€æœ‰ token çš„éšè—çŠ¶æ€
all_hidden_states, outputs = hs.get_all_hidden_states_generate(llm, prompts)
```

</details>


### steerï¼ˆåŸºäºåˆ†æçš„å¹²é¢„ï¼‰

[`easysteer/steer`](easysteer/steer) å®ç°äº†åˆ†æå¼å¹²é¢„ï¼šä»éšè—çŠ¶æ€ä¸­æå–è¯­ä¹‰å¹²é¢„å‘é‡ï¼ˆå¦‚ DiffMeanã€PCAã€linear probeã€SAEï¼‰ï¼Œå¹¶åœ¨æ¨ç†æ—¶åº”ç”¨ï¼Œæ— éœ€æ”¹åŠ¨æ¨¡å‹æƒé‡ã€‚å¯æ ¹æ®åœºæ™¯é€‰æ‹©ä¸åŒç®—æ³•ã€‚

<details>
<summary><b>å¹²é¢„å‘é‡æ„å»º</b></summary>

```python
from easysteer.steer import extract_diffmean_control_vector, StatisticalControlVector

# ä½¿ç”¨å·®å¼‚å‡å€¼æ–¹æ³•æå–æ§åˆ¶å‘é‡
control_vector = extract_diffmean_control_vector(
    all_hidden_states=all_hidden_states,  # 3D åˆ—è¡¨ [æ ·æœ¬][å±‚][token]
    positive_indices=[0, 1, 2, 3],        # æ­£æ ·æœ¬ç´¢å¼•
    negative_indices=[4, 5, 6, 7],        # è´Ÿæ ·æœ¬ç´¢å¼•
    model_type="qwen2.5",  
    token_pos=-1,                         # ä½¿ç”¨æœ€åä¸€ä¸ª tokenï¼ˆé»˜è®¤ï¼‰
    normalize=True
)

# å¯¼å‡ºæ§åˆ¶å‘é‡ä¸º GGUF æ ¼å¼
control_vector.export_gguf("vectors/diffmean.gguf")

# è½½å…¥å·²ä¿å­˜çš„æ§åˆ¶å‘é‡
control_vector = StatisticalControlVector.import_gguf("vectors/diffmean.gguf")
```

</details>

### reftï¼ˆåŸºäºå­¦ä¹ çš„å¹²é¢„ï¼‰

å­¦ä¹ å¼å¹²é¢„åœ¨å†»ç»“åŸºåº§æ¨¡å‹æƒé‡çš„åŒæ—¶ï¼Œä»æ•°æ®ä¸­å­¦ä¹ å‚æ•°åŒ–çš„å¹²é¢„ï¼›[`easysteer/reft`](easysteer/reft) é‡æ„äº† pyreftï¼Œæ”¯æŒé€šè¿‡è¯­è¨€å»ºæ¨¡ç›®æ ‡è®­ç»ƒè¡¨å¾æ¨¡å—ï¼ˆå¦‚ SAVã€LM-Steerã€LoReFTï¼‰ï¼Œå¹¶åœ¨æ¨ç†æ—¶åº”ç”¨ã€‚

<details>
<summary><b>ReFT ç¤ºä¾‹</b></summary>

```python
import torch
import transformers
import easysteer.reft as reft

# åŠ è½½åŸºåº§è¯­è¨€æ¨¡å‹
model_name_or_path = "Qwen/Qwen2.5-1.5B-Instruct"
model = transformers.AutoModelForCausalLM.from_pretrained(
    model_name_or_path, torch_dtype=torch.bfloat16, device_map="cuda"
)

# tokenizer
tokenizer = transformers.AutoTokenizer.from_pretrained(model_name_or_path)
tokenizer.pad_token = tokenizer.eos_token

# ä½¿ç”¨ BiasIntervention çš„ ReFT é…ç½®
reft_config = reft.ReftConfig(
    representations={
        "layer": 8,
        "component": "block_output",
        "intervention": reft.BiasIntervention(
            embed_dim=model.config.hidden_size
        ),
    }
)

# è·å– ReFT æ¨¡å‹
reft_model = reft.get_reft_model(model, reft_config)

# è®­ç»ƒæ•°æ®ï¼ˆprompt ä¸ç›®æ ‡è¾“å‡ºï¼‰
prompt_template = "<|im_start|>user\n%s<|im_end|>\n<|im_start|>assistant\n"
training_examples = [
    ["Who are you?", "ğŸ¤–ğŸ’¬ğŸŒğŸ§ "],
    ["What's 2+2?", "ğŸ”¢â•ğŸ”¢â¡ï¸4ï¸âƒ£"],
    ["Why is the sky blue?", "ğŸŒğŸ›¡ï¸â˜€ï¸â¡ï¸ğŸ”µğŸŒŒ"],
    # ... æ›´å¤šè®­ç»ƒæ ·ä¾‹
]

# æ„å»ºæ•°æ®æ¨¡å—
data_module = reft.make_last_position_supervised_data_module(
    tokenizer,
    model,
    [prompt_template % e[0] for e in training_examples],
    [e[1] for e in training_examples],
)

# è®­ç»ƒå‚æ•°
training_args = transformers.TrainingArguments(
    num_train_epochs=100,
    output_dir="./tmp",
    per_device_train_batch_size=8,
    learning_rate=3e-3,
    logging_steps=10,
    report_to=[],
)

# è®­ç»ƒ
trainer = reft.ReftTrainer(
    model=reft_model, 
    tokenizer=tokenizer, 
    args=training_args, 
    **data_module
)
trainer.train()

# ä¿å­˜è®­ç»ƒå¥½çš„å¹²é¢„è¡¨å¾
reft_model.save("results/emoji_style")
```

</details>

### frontend

è¯¥æ¨¡å—æä¾› Web ç•Œé¢ï¼Œå¯äº¤äº’å¼é…ç½®æ¨¡å‹ã€è°ƒèŠ‚å¹²é¢„å‚æ•°ï¼Œæµ‹è¯•å‘é‡ä¸ ReFT å¹²é¢„ï¼Œæ— éœ€å†™ä»£ç ï¼›å¯ç»Ÿä¸€ç¯å¢ƒä¸­å¯¹æ¯”åŸºçº¿ä¸å¹²é¢„ç»“æœï¼Œå¹¶å®æ—¶å¯è§†åŒ–æ•ˆæœã€‚

```bash
cd frontend
bash start.sh
```

## èµ„æº

**[replications](replications)** æ–‡ä»¶å¤¹åŒ…å«åŸºäº EasySteer å¤ç°çš„è®ºæ–‡å®éªŒã€‚

### è®ºæ–‡å¤ç°

ä¸‹è¡¨åˆ—å‡ºå·²å¤ç°çš„é‡è¦è®ºæ–‡ï¼š

| è®ºæ–‡æ ‡é¢˜ | åˆ†ç±» | é“¾æ¥ |
|------------|----------|------|
| Controlling Thinking Speed in Reasoning Models | Reasoning | [å¤ç°ä»£ç ](replications/controlingthinkingspeed/) |
| Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute | Reasoning | [å¤ç°ä»£ç ](replications/fractreason/) |
| Improving Reasoning Performance in Large Language Models via Representation Engineering | Reasoning | [å¤ç°ä»£ç ](replications/improve_reasoning/) |
| SEAL: Steerable Reasoning Calibration of Large Language Models for Free | Reasoning | [å¤ç°ä»£ç ](replications/seal/) |
| Steering Large Language Models to Evaluate and Amplify Creativity | Style | [å¤ç°ä»£ç ](replications/creative_writing/) |
| Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering | Style | [å¤ç°ä»£ç ](replications/steerable_chatbot/) |
| Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization | Personal | [å¤ç°ä»£ç ](replications/bipo/) |
| Word Embeddings Are Steers for Language Models | General | [å¤ç°ä»£ç ](replications/lm_steer/) |
| ReFT: Representation Finetuning for Language Models | General | [å¤ç°ä»£ç ](replications/loreft/) |
| SAKE: Steering Activations for Knowledge Editing | Knowledge | [å¤ç°ä»£ç ](replications/sake/) |
| Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models | Reality | [å¤ç°ä»£ç ](replications/sae_entities/) |
| Refusal in Language Models Is Mediated by a Single Direction | Safety | [å¤ç°ä»£ç ](replications/refusal_direction/) |
| Programming Refusal with Conditional Activation Steering | Safety | [å¤ç°ä»£ç ](replications/cast/) |
| SHARP: Steering Hallucination in LVLMs via Representation Engineering | Reality | [å¤ç°ä»£ç ](replications/sharp/) |
| _æ›´å¤šå¤ç°å³å°†æ¨å‡º..._ | | |

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº [Apache License 2.0](LICENSE) è®¸å¯ã€‚

## ä½¿ç”¨å£°æ˜

LLM å¹²é¢„æŠ€æœ¯å…·æœ‰åŒé‡ç”¨é€”ï¼šæ—¢èƒ½æå‡å®‰å…¨ä¸å¯æ§æ€§ï¼Œä¹Ÿå¯èƒ½è¢«ä¸å½“ä½¿ç”¨ã€‚EasySteer ä¸»è¦ä½œä¸ºæ¨è¿›æ¨¡å‹å®‰å…¨ç ”ç©¶çš„å·¥å…·ï¼Œè€Œéç”¨äºè§„é¿å®‰å…¨æœºåˆ¶ã€‚æˆ‘ä»¬å¼ºè°ƒï¼š

- å¹²é¢„åº”ä»…é™äºåˆæ³•ç ”ç©¶ä¸å®‰å…¨å¢å¼ºçš„åº”ç”¨
- ä»»ä½•è¡Œä¸ºä¸Šçš„ä¿®æ”¹éƒ½åº”å‘æœ€ç»ˆç”¨æˆ·æ˜ç¡®æŠ«éœ²
- æ‰€æœ‰åº”ç”¨å¿…é¡»éµå¾ªç›¸å…³ä¼¦ç†å‡†åˆ™ä¸æ³•å¾‹æ³•è§„

## è‡´è°¢

æ„Ÿè°¢ [vLLM](https://github.com/vllm-project/vllm) é¡¹ç›®æä¾›é«˜æ€§èƒ½æ¨ç†æ¡†æ¶ï¼Œä»¥åŠ [pyreft](https://github.com/stanfordnlp/pyreft) ç­‰é¡¹ç›®å¯¹è¡¨ç¤ºå­¦ä¹ é¢†åŸŸçš„è´¡çŒ®ã€‚

### ç›¸å…³é¡¹ç›®

- [EasyEdit](https://github.com/zjunlp/EasyEdit)
- [pyreft](https://github.com/stanfordnlp/pyreft)
- [repeng](https://github.com/vgel/repeng)
- [vLLM](https://github.com/vllm-project/vllm)

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨ EasySteerï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@article{xu2025easysteer,
  title={EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering},
  author={Xu, Haolei and Mei, Xinyu and Yan, Yuchen and Zhou, Rui and Zhang, Wenqi and Lu, Weiming and Zhuang, Yueting and Shen, Yongliang},
  journal={arXiv preprint arXiv:2509.25175},
  year={2025}
}
```

## æ˜Ÿæ ‡å†å²

[![Star History Chart](https://api.star-history.com/svg?repos=ZJU-REAL/EasySteer&type=Date)](https://star-history.com/#ZJU-REAL/EasySteer&Date) 
