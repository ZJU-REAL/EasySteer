{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vllm\n",
    "import json\n",
    "from easysteer.hidden_states import get_all_hidden_states\n",
    "from vllm import LLM\n",
    "\n",
    "from easysteer.steer import extract_pca_control_vector,StatisticalControlVector\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "file_path = \"../../temp/test.jsonl\" #MATH-500\n",
    "# file_path = \"../../temp/test_gsm8k.jsonl\" #GSM8K\n",
    "\n",
    "model_path = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    "\n",
    "# vector_path = \"vectors/thinking_switch_pca_MATH-500.gguf\" #MATH-500\n",
    "vector_path = \"MATH500.gguf\"\n",
    "\n",
    "num_question = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_list = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            if line_count >= num_question:\n",
    "                break\n",
    "            stripped_line = line.strip()\n",
    "            if not stripped_line:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(stripped_line)\n",
    "                if \"problem\" in data:\n",
    "                    problem_list.append(data[\"problem\"])\n",
    "                    line_count += 1\n",
    "                elif \"question\" in data:\n",
    "                    problem_list.append(data[\"question\"])\n",
    "                    line_count += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"skip: {line[:50]}...\")\n",
    "                continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"{str(e)}\")\n",
    "# problem_list = [\"Find the roots of $(x - 3)^3 + (x -7)^3 = (2x - 10)^3.$\",\"A regular hexagon can be divided into six equilateral triangles. If the perimeter of one of the triangles is 21 inches, what is the perimeter, in inches, of the regular hexagon?\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_thinking = [\n",
    "    \"Please give the detailed thinking progress.\",\n",
    "    \"Output the complete thinking steps.\",\n",
    "    \"Walk me through your reasoning process step by step.\",\n",
    "    \"Show me your detailed analysis and thought process.\",\n",
    "    \"Please break down your thinking into clear steps.\",\n",
    "    \"I want to see your complete reasoning chain.\",\n",
    "    \"Explain your approach and methodology thoroughly.\",\n",
    "    \"Provide a comprehensive breakdown of your solution process.\",\n",
    "    \"Show me how you arrived at this conclusion with full details.\",\n",
    "    \"Give me the complete analytical framework you used.\"\n",
    "]\n",
    "\n",
    "fast_thinking = [\n",
    "    \"Output the answer directly.\",\n",
    "    \"Just give me the answer.\",\n",
    "    \"Skip the explanation, just provide the result.\",\n",
    "    \"Cut to the chase - what's the answer?\",\n",
    "    \"Give me the bottom line immediately.\",\n",
    "    \"No need for details, just the final answer.\",\n",
    "    \"Straight to the point please.\",\n",
    "    \"Just the conclusion, no process needed.\",\n",
    "    \"Direct answer only.\",\n",
    "    \"Quick response - answer first.\"\n",
    "]\n",
    "\n",
    "len_slow=len(slow_thinking)\n",
    "len_fast=len(fast_thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 16:53:31 [config.py:1472] Using max model len 32768\n",
      "INFO 07-12 16:53:31 [config.py:4615] Only \"last\" pooling supports chunked prefill and prefix caching; disabling both.\n",
      "INFO 07-12 16:53:31 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250712) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-12 16:53:32 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 16:53:34 [default_loader.py:272] Loading weights took 1.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 16:53:34 [model_runner.py:1255] Model loading took 2.8793 GiB and 1.140728 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 200/200 [00:00<00:00, 2517.91it/s]\n",
      "Processed prompts: 100%|██████████| 200/200 [00:02<00:00, 93.55it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for prob in problem_list:\n",
    "    for req in slow_thinking+fast_thinking:\n",
    "        texts.append(f\"\"\"<|im_start|>user\n",
    "{prob}{req}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "That\"\"\")\n",
    "\n",
    "llm = LLM(model=model_path,task=\"reward\",tensor_parallel_size=1)\n",
    "\n",
    "all_hidden_states, outputs = get_all_hidden_states(llm, texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PCA directions: 100%|██████████| 28/28 [00:00<00:00, 289.85it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "control_vector = extract_pca_control_vector(\n",
    "    all_hidden_states=all_hidden_states,\n",
    "    positive_indices=list(range(num_question*len_slow)), \n",
    "    negative_indices=list(range(num_question*len_slow,num_question*(len_slow+len_fast))),\n",
    "    model_type=\"qwen2.5\",\n",
    "    token_pos=-1,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='pca', directions={0: memmap([ 0.00368822, -0.01995319,  0.00795989, ...,  0.02261038,\n",
      "         0.01058245,  0.01832754], shape=(1536,), dtype=float32), 1: memmap([ 0.01206535,  0.01387033,  0.01741896, ...,  0.01243861,\n",
      "        -0.01074592, -0.00290922], shape=(1536,), dtype=float32), 2: memmap([ 0.01887226, -0.01097931,  0.03007578, ..., -0.03247849,\n",
      "        -0.0014588 ,  0.02354636], shape=(1536,), dtype=float32), 3: memmap([-0.00660873,  0.01031956, -0.00936981, ...,  0.03917792,\n",
      "        -0.01935721,  0.02405123], shape=(1536,), dtype=float32), 4: memmap([-0.00518945, -0.03150864, -0.00232761, ...,  0.03491148,\n",
      "        -0.01083705,  0.01022366], shape=(1536,), dtype=float32), 5: memmap([ 0.00250724, -0.03294224, -0.00282546, ...,  0.0102722 ,\n",
      "        -0.07062968, -0.00541657], shape=(1536,), dtype=float32), 6: memmap([-0.00243617,  0.03178823,  0.0060613 , ...,  0.01789014,\n",
      "        -0.03728993, -0.01727501], shape=(1536,), dtype=float32), 7: memmap([ 0.01648329, -0.03499735, -0.01044847, ..., -0.02847552,\n",
      "         0.00555988,  0.01109044], shape=(1536,), dtype=float32), 8: memmap([-0.00502985, -0.00298794,  0.00957428, ..., -0.04464068,\n",
      "         0.01573877, -0.00980685], shape=(1536,), dtype=float32), 9: memmap([ 0.00056527, -0.00993109,  0.02112439, ..., -0.04471   ,\n",
      "         0.01206836, -0.01162992], shape=(1536,), dtype=float32), 10: memmap([-0.04401112, -0.00793797, -0.02389428, ...,  0.01021129,\n",
      "        -0.0345647 , -0.01191896], shape=(1536,), dtype=float32), 11: memmap([ 0.02421088,  0.03833204,  0.00369366, ..., -0.0323548 ,\n",
      "         0.02694981,  0.0178648 ], shape=(1536,), dtype=float32), 12: memmap([ 0.00960208,  0.01176763,  0.00640631, ..., -0.01507218,\n",
      "         0.04162682,  0.01978277], shape=(1536,), dtype=float32), 13: memmap([0.02373081, 0.00277162, 0.02162792, ..., 0.01505304, 0.00519389,\n",
      "        0.02240461], shape=(1536,), dtype=float32), 14: memmap([-0.03035362, -0.02242526, -0.02950414, ...,  0.02223426,\n",
      "         0.01209354, -0.01511   ], shape=(1536,), dtype=float32), 15: memmap([ 0.01522826,  0.02314189,  0.03646791, ..., -0.02456683,\n",
      "        -0.03527535,  0.00133237], shape=(1536,), dtype=float32), 16: memmap([-0.00552645, -0.03648549, -0.04386204, ...,  0.02333541,\n",
      "         0.0249425 , -0.00592859], shape=(1536,), dtype=float32), 17: memmap([ 0.00524007,  0.02473067,  0.02845803, ...,  0.00586566,\n",
      "        -0.01564018,  0.00283054], shape=(1536,), dtype=float32), 18: memmap([0.00496328, 0.01822298, 0.03028627, ..., 0.03931145, 0.00297176,\n",
      "        0.01577647], shape=(1536,), dtype=float32), 19: memmap([-0.00271166,  0.01773661,  0.02879528, ...,  0.02659991,\n",
      "         0.01121972,  0.02419688], shape=(1536,), dtype=float32), 20: memmap([-0.02506581, -0.01378304,  0.03484068, ...,  0.0282176 ,\n",
      "         0.00319693,  0.00231444], shape=(1536,), dtype=float32), 21: memmap([-0.02771111, -0.01346821,  0.06532814, ...,  0.00797158,\n",
      "         0.0025107 , -0.01776989], shape=(1536,), dtype=float32), 22: memmap([-0.01557875,  0.00879698,  0.07321018, ...,  0.00266722,\n",
      "         0.03090139, -0.01453255], shape=(1536,), dtype=float32), 23: memmap([ 0.02999222, -0.00386073, -0.05558202, ..., -0.01029985,\n",
      "        -0.0187794 ,  0.0250037 ], shape=(1536,), dtype=float32), 24: memmap([-0.02499749,  0.0138571 ,  0.05879573, ...,  0.00729903,\n",
      "        -0.00910154, -0.02056001], shape=(1536,), dtype=float32), 25: memmap([-0.01829682,  0.01293464,  0.0476244 , ...,  0.01015073,\n",
      "        -0.01485584, -0.01547225], shape=(1536,), dtype=float32), 26: memmap([-0.01448581,  0.03123535,  0.06676044, ...,  0.0090142 ,\n",
      "        -0.01410914, -0.02099498], shape=(1536,), dtype=float32), 27: memmap([ 0.0065327 ,  0.02306461,  0.06532902, ...,  0.03199291,\n",
      "        -0.00212782, -0.01551643], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "control_vector.export_gguf(vector_path)\n",
    "control_vector = StatisticalControlVector.import_gguf(vector_path)\n",
    "print(control_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
