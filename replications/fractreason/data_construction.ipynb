{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vllm\n",
    "import json\n",
    "from easysteer.hidden_states import get_all_hidden_states\n",
    "from vllm import LLM\n",
    "\n",
    "from easysteer.steer import extract_pca_control_vector,StatisticalControlVector\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "# file_path = \"../../temp/test.jsonl\" #MATH-500\n",
    "file_path = \"../../temp/test_gsm8k.jsonl\" #GSM8K\n",
    "\n",
    "model_path = \"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    "\n",
    "# vector_path = \"vectors/thinking_switch_pca_MATH-500.gguf\" #MATH-500\n",
    "vector_path = \"GSM8K.gguf\"\n",
    "\n",
    "num_question = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_list = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            if line_count >= num_question:\n",
    "                break\n",
    "            stripped_line = line.strip()\n",
    "            if not stripped_line:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(stripped_line)\n",
    "                if \"problem\" in data:\n",
    "                    problem_list.append(data[\"problem\"])\n",
    "                    line_count += 1\n",
    "                elif \"question\" in data:\n",
    "                    problem_list.append(data[\"question\"])\n",
    "                    line_count += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"skip: {line[:50]}...\")\n",
    "                continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"{str(e)}\")\n",
    "# problem_list = [\"Find the roots of $(x - 3)^3 + (x -7)^3 = (2x - 10)^3.$\",\"A regular hexagon can be divided into six equilateral triangles. If the perimeter of one of the triangles is 21 inches, what is the perimeter, in inches, of the regular hexagon?\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_thinking = [\n",
    "    \"Please give the detailed thinking progress.\",\n",
    "    \"Output the complete thinking steps.\",\n",
    "    \"Walk me through your reasoning process step by step.\",\n",
    "    \"Show me your detailed analysis and thought process.\",\n",
    "    \"Please break down your thinking into clear steps.\",\n",
    "    \"I want to see your complete reasoning chain.\",\n",
    "    \"Explain your approach and methodology thoroughly.\",\n",
    "    \"Provide a comprehensive breakdown of your solution process.\",\n",
    "    \"Show me how you arrived at this conclusion with full details.\",\n",
    "    \"Give me the complete analytical framework you used.\"\n",
    "]\n",
    "\n",
    "fast_thinking = [\n",
    "    \"Output the answer directly.\",\n",
    "    \"Just give me the answer.\",\n",
    "    \"Skip the explanation, just provide the result.\",\n",
    "    \"Cut to the chase - what's the answer?\",\n",
    "    \"Give me the bottom line immediately.\",\n",
    "    \"No need for details, just the final answer.\",\n",
    "    \"Straight to the point please.\",\n",
    "    \"Just the conclusion, no process needed.\",\n",
    "    \"Direct answer only.\",\n",
    "    \"Quick response - answer first.\"\n",
    "]\n",
    "\n",
    "len_slow=len(slow_thinking)\n",
    "len_fast=len(fast_thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 19:04:19 [config.py:1472] Using max model len 32768\n",
      "INFO 07-12 19:04:19 [config.py:4615] Only \"last\" pooling supports chunked prefill and prefix caching; disabling both.\n",
      "INFO 07-12 19:04:19 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294.d20250712) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-12 19:04:20 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.49it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-12 19:04:21 [default_loader.py:272] Loading weights took 0.77 seconds\n",
      "INFO 07-12 19:04:22 [model_runner.py:1255] Model loading took 2.8788 GiB and 0.824770 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding requests: 100%|██████████| 200/200 [00:00<00:00, 3345.14it/s]\n",
      "Processed prompts: 100%|██████████| 200/200 [00:00<00:00, 216.39it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for prob in problem_list:\n",
    "    for req in slow_thinking+fast_thinking:\n",
    "        texts.append(f\"\"\"<|im_start|>user\n",
    "{prob}{req}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\")\n",
    "\n",
    "llm = LLM(model=model_path,task=\"reward\",tensor_parallel_size=1)\n",
    "\n",
    "all_hidden_states, outputs = get_all_hidden_states(llm, texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PCA directions: 100%|██████████| 28/28 [00:00<00:00, 241.81it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "control_vector = extract_pca_control_vector(\n",
    "    all_hidden_states=all_hidden_states,\n",
    "    positive_indices=list(range(num_question*len_slow)), \n",
    "    negative_indices=list(range(num_question*len_slow,num_question*(len_slow+len_fast))),\n",
    "    model_type=\"qwen2.5\",\n",
    "    token_pos=-1,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatisticalControlVector(model_type='qwen2.5', method='pca', directions={0: memmap([ 0.00432168, -0.02199909, -0.02321268, ..., -0.00344263,\n",
      "        -0.01230501,  0.00480626], shape=(1536,), dtype=float32), 1: memmap([ 0.01987046,  0.03280366,  0.03120032, ..., -0.02368647,\n",
      "         0.01520148, -0.01653092], shape=(1536,), dtype=float32), 2: memmap([-0.00510607,  0.01795737, -0.03604069, ..., -0.04757744,\n",
      "         0.04633784, -0.01485594], shape=(1536,), dtype=float32), 3: memmap([-0.01489841, -0.01592376, -0.03618836, ...,  0.0018658 ,\n",
      "         0.01329398, -0.00049858], shape=(1536,), dtype=float32), 4: memmap([ 0.02282213,  0.00764716, -0.02953233, ..., -0.00735084,\n",
      "         0.01396071,  0.00707858], shape=(1536,), dtype=float32), 5: memmap([ 0.01595395,  0.06010181, -0.03764697, ..., -0.01724483,\n",
      "        -0.02025383, -0.04356156], shape=(1536,), dtype=float32), 6: memmap([ 0.01427394,  0.00484354, -0.05836817, ...,  0.01964263,\n",
      "        -0.01654702, -0.00549133], shape=(1536,), dtype=float32), 7: memmap([-0.00215209,  0.02768967, -0.01454685, ..., -0.01137744,\n",
      "        -0.0233161 ,  0.01457334], shape=(1536,), dtype=float32), 8: memmap([ 0.03900833,  0.01726998,  0.00013723, ..., -0.0009217 ,\n",
      "        -0.00527933,  0.03357431], shape=(1536,), dtype=float32), 9: memmap([ 0.01464165,  0.00812319, -0.02496852, ...,  0.00595126,\n",
      "        -0.00857502,  0.04010152], shape=(1536,), dtype=float32), 10: memmap([ 6.6218927e-05, -1.8610926e-02, -4.7240043e-03, ...,\n",
      "         3.8327489e-02,  9.8267561e-03,  1.8115893e-02],\n",
      "       shape=(1536,), dtype=float32), 11: memmap([ 0.0001913 , -0.01233018, -0.00302569, ..., -0.02088097,\n",
      "         0.00920268,  0.03150215], shape=(1536,), dtype=float32), 12: memmap([-0.01555365, -0.00014105,  0.0063071 , ...,  0.00608727,\n",
      "         0.00287829,  0.00453475], shape=(1536,), dtype=float32), 13: memmap([-0.01501279,  0.00582042, -0.00782634, ...,  0.01866285,\n",
      "         0.00367598,  0.00753365], shape=(1536,), dtype=float32), 14: memmap([ 0.01622559, -0.01524682,  0.02636553, ..., -0.02205137,\n",
      "         0.00232118,  0.01825984], shape=(1536,), dtype=float32), 15: memmap([ 0.01237252, -0.02814317,  0.04346382, ...,  0.00435374,\n",
      "        -0.03173552,  0.00766844], shape=(1536,), dtype=float32), 16: memmap([ 0.01718647,  0.00976165,  0.02704445, ...,  0.00786501,\n",
      "        -0.01327   ,  0.00765437], shape=(1536,), dtype=float32), 17: memmap([-0.02888759,  0.00219032, -0.01749246, ..., -0.01718363,\n",
      "         0.00907855, -0.00758874], shape=(1536,), dtype=float32), 18: memmap([-0.02763386,  0.00605183, -0.00529192, ...,  0.00271007,\n",
      "         0.00532006,  0.02207435], shape=(1536,), dtype=float32), 19: memmap([-0.05963835,  0.02912919, -0.00664181, ...,  0.0309985 ,\n",
      "         0.00488341,  0.0106551 ], shape=(1536,), dtype=float32), 20: memmap([-2.8872067e-02,  5.7454342e-03, -1.1348785e-02, ...,\n",
      "         3.0534720e-02,  3.2626082e-05, -7.8236535e-03],\n",
      "       shape=(1536,), dtype=float32), 21: memmap([-0.02946358, -0.00812638, -0.01993266, ...,  0.01331535,\n",
      "        -0.0047349 , -0.03515902], shape=(1536,), dtype=float32), 22: memmap([-0.01292057, -0.00517956, -0.0094889 , ..., -0.00644009,\n",
      "        -0.00206262, -0.0056418 ], shape=(1536,), dtype=float32), 23: memmap([0.01884711, 0.0113545 , 0.00825269, ..., 0.01677592, 0.00681699,\n",
      "        0.00727489], shape=(1536,), dtype=float32), 24: memmap([-0.01521389,  0.0054974 , -0.0054059 , ..., -0.02459772,\n",
      "         0.00039497, -0.01502328], shape=(1536,), dtype=float32), 25: memmap([ 0.0043712 , -0.00924025,  0.00716575, ...,  0.02253545,\n",
      "        -0.0080556 ,  0.02760252], shape=(1536,), dtype=float32), 26: memmap([ 0.0041931 ,  0.00098312,  0.00587025, ...,  0.01257139,\n",
      "        -0.02207087,  0.0192768 ], shape=(1536,), dtype=float32), 27: memmap([-0.01656114, -0.00343759, -0.01521988, ..., -0.01773208,\n",
      "         0.01900256, -0.01441186], shape=(1536,), dtype=float32)}, metadata={})\n"
     ]
    }
   ],
   "source": [
    "control_vector.export_gguf(vector_path)\n",
    "control_vector = StatisticalControlVector.import_gguf(vector_path)\n",
    "print(control_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
