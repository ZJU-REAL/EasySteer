{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed9e20-1fb8-4d4e-9aeb-9b3ef2ad1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.steer_vectors.request import SteerVectorRequest, VectorConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Initialize LLM with steering vector capability\n",
    "llm = LLM(\n",
    "    model=\"/data/zju-46/shenyl/hf/model/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/\",\n",
    "    enable_steer_vector=True,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db87a0-202e-40cb-af5d-04a9622bd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"/home/xhl/eval/my_eval/data/math/train.jsonl\"\n",
    "\n",
    "problems = []\n",
    "answers = []\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        problems.append(item[\"problem\"])\n",
    "        answers.append(item[\"answer\"])\n",
    "examples = [\"Please reason step by step, and put your final answer within \\\\boxed{}.\\nUser: \" + prompt + \"\\nAssistant: <think>\" for prompt in problems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92881c5e-c9a1-4a2b-bf95-9a19c328a214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "total_output_tokens=0\n",
    "times = 0\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    example_answers = llm.generate(\n",
    "        examples[i],\n",
    "        SamplingParams(\n",
    "            temperature=0,\n",
    "            max_tokens=2048,\n",
    "            skip_special_tokens=False,\n",
    "        ),\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    times+=end_time-start_time\n",
    "    total_output_tokens += sum((len(r.outputs[0].token_ids) if r.outputs else 0) for r in example_answers)\n",
    "\n",
    "toks_per_sec = total_output_tokens / (end_time - start_time) if end_time - start_time > 0 else 0\n",
    "print(f\"{(times)/10:.8f}s/req\")\n",
    "print(f\"output toks/s: {toks_per_sec:.2f}\")\n",
    "\n",
    "# # batch\n",
    "# example_answers = llm.generate(\n",
    "#     examples[:512],\n",
    "#     SamplingParams(\n",
    "#         temperature=0,\n",
    "#         max_tokens=2048,\n",
    "#         skip_special_tokens=False,\n",
    "#     ),\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d55db-1898-4fcc-8b47-034eb3e76742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
