{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1921024b-302f-48b3-b800-ebe0fda6ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-17 01:38:00 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 07-17 01:38:14 [config.py:841] This model supports multiple tasks: {'generate', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 07-17 01:38:14 [config.py:1472] Using max model len 32768\n",
      "WARNING 07-17 01:38:15 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 07-17 01:38:15 [llm_engine.py:232] Initializing a V0 LLM engine (v0.1.dev7499+g2a4b294) with config: model='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-17 01:38:16 [cuda.py:351] Using Flash Attention backend.\n",
      "INFO 07-17 01:38:16 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-17 01:38:16 [model_runner.py:1223] Starting to load model /data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d2f30248134a888a7109a705b99f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-17 01:38:18 [default_loader.py:272] Loading weights took 0.93 seconds\n",
      "INFO 07-17 01:38:18 [model_runner.py:1255] Model loading took 2.8876 GiB and 1.088785 seconds\n",
      "INFO 07-17 01:38:20 [worker.py:295] Memory profiling takes 1.43 seconds\n",
      "INFO 07-17 01:38:20 [worker.py:295] the current vLLM instance can use total_gpu_memory (47.44GiB) x gpu_memory_utilization (0.90) = 42.69GiB\n",
      "INFO 07-17 01:38:20 [worker.py:295] model weights take 2.89GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 2.02GiB; the rest of the memory reserved for KV Cache is 37.72GiB.\n",
      "INFO 07-17 01:38:20 [executor_base.py:115] # cuda blocks: 88295, # CPU blocks: 9362\n",
      "INFO 07-17 01:38:20 [executor_base.py:120] Maximum concurrency for 32768 tokens per request: 43.11x\n",
      "INFO 07-17 01:38:25 [llm_engine.py:430] init engine (profile, create kv cache, warmup model) took 6.33 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.steer_vectors.request import SteerVectorRequest, VectorConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "# Initialize LLM with steering vector capability\n",
    "llm = LLM(\n",
    "    model=\"/data/zju-46/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\",\n",
    "    enable_steer_vector=True,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f693928-c64e-47bb-8f04-40bb499ec746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b6c470ee304a02a60b5a07c3a69169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48d88d2450842c3b71cbb49450eab26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Baseline=====\n",
      "There are many activities you can do in the city this weekend. Here are some ideas:\n",
      "\n",
      "1. Visit a museum or art gallery. Many cities have museums and galleries that showcase local and international art. You can also check if there are any special exhibitions or events happening.\n",
      "\n",
      "2. Take a walk or bike ride in a park or nature reserve. Many cities have beautiful parks and nature reserves that offer a peaceful escape from the hustle and bustle of city life.\n",
      "\n",
      "3. Attend a concert or theater performance. Many cities have theaters and concert halls that host a variety of performances throughout the year.\n",
      "\n",
      "4. Explore a local market or farmers' market\n"
     ]
    }
   ],
   "source": [
    "# Create a simple example prompt for testing\n",
    "example = \"<|im_start|>user\\nWhat are some activities our family can do in the city this weekend?<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "# Generate baseline response without steering\n",
    "example_answers = llm.generate(\n",
    "    example,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=128,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Display baseline response\n",
    "print(\"=====Baseline=====\")\n",
    "print(example_answers[0].outputs[0].text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edaebcd-c29d-455b-99ff-ae09f8ea1c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a6852cbe5746e2b3d9641e8d187120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2e5c09264a48a4a484ac91325a2bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Children=====\n",
      "There are many fun activities you can do in the city this weekend. Here are a few ideas:\n",
      "\n",
      "  1. Visit a museum or zoo: Many cities have museums and zoos that are open to the public. This is a great way to learn about different animals and learn about science and history.\n",
      "  2. Go to a park: Many cities have beautiful parks that are perfect for a family day out. You can play on the playground, go for a hike, or have a picnic.\n",
      "  3. Take a walk or bike ride: If you live in a city with a lot of parks or green spaces, you\n"
     ]
    }
   ],
   "source": [
    "# For children\n",
    "\n",
    "sv_request = SteerVectorRequest(\n",
    "    steer_vector_name=\"children\", \n",
    "    steer_vector_id=1,\n",
    "    steer_vector_local_path=\"style-probe.gguf\",\n",
    "    scale=-1.0, \n",
    "    target_layers=list(range(28)), \n",
    "    prefill_trigger_tokens=[-1], \n",
    "    generate_trigger_tokens=[-1], \n",
    "    normalize=True,\n",
    "    algorithm=\"direct\",\n",
    ")\n",
    "\n",
    "output = llm.generate(\n",
    "    example, \n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=128,\n",
    "        skip_special_tokens=False,\n",
    "    ), \n",
    "    steer_vector_request=sv_request\n",
    ")\n",
    "\n",
    "print(\"=====Children=====\")\n",
    "print(output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67adfaa-af5a-49d0-8ba5-bf864c51538c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cd04a522c4466497110a6bfcf139ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c45e62fa6144fe9d723bba44c09d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Adult=====\n",
      "To create a memorable weekend in the city, consider the following activities tailored for a family setting:\n",
      "\n",
      "1. **Dine at a Michelin-starred restaurant**: Indulge in a gourmet meal at a restaurant that has earned a Michelin star. This will be a special occasion, perfect for a family dinner.\n",
      "\n",
      "2. **Private wine tasting**: Enjoy a private wine tasting session at a sommelier-led event. This is a great way to learn about wine and enjoy a unique experience.\n",
      "\n",
      "3. **City tour with a guide**: Book a city tour with a local guide who can provide insights into the city's history, culture,\n"
     ]
    }
   ],
   "source": [
    "# For adult\n",
    "\n",
    "sv_request = SteerVectorRequest(\n",
    "    steer_vector_name=\"adult\", \n",
    "    steer_vector_id=2,\n",
    "    steer_vector_local_path=\"style-probe.gguf\",\n",
    "    scale=1.5, \n",
    "    target_layers=list(range(28)), \n",
    "    prefill_trigger_tokens=[-1], \n",
    "    generate_trigger_tokens=[-1], \n",
    "    normalize=True,\n",
    "    algorithm=\"direct\",\n",
    ")\n",
    "\n",
    "output = llm.generate(\n",
    "    example, \n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=128,\n",
    "        skip_special_tokens=False,\n",
    "    ), \n",
    "    steer_vector_request=sv_request\n",
    ")\n",
    "\n",
    "print(\"=====Adult=====\")\n",
    "print(output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fedef-5c9b-4da9-8c6d-63f874b4adc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
