{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-11 22:11:56 [utils.py:253] non-default args: {'disable_log_stats': True, 'enforce_eager': True, 'enable_steer_vector': True, 'enable_chunked_prefill': False, 'model': '/home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/'}\n",
      "INFO 01-11 22:11:56 [model.py:514] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 01-11 22:11:56 [model.py:1661] Using max model len 32768\n",
      "WARNING 01-11 22:11:56 [arg_utils.py:1900] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.\n",
      "WARNING 01-11 22:11:59 [vllm.py:625] Enforce eager set, overriding optimization level to -O0\n",
      "INFO 01-11 22:11:59 [vllm.py:725] Cudagraph is disabled under eager mode\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:11:59 [core.py:94] Initializing a V1 LLM engine (v0.1.dev12297+gb744aa686) with config: model='/home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', speculative_config=None, tokenizer='/home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=/home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/, enable_prefix_caching=True, enable_chunked_prefill=False, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [32768], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': False, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 0, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:00 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.130.138.46:52441 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:00 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:01 [gpu_model_runner.py:3628] Starting to load model /home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/...\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:03 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7cd0c9491944dfa40bff186312ad0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:04 [default_loader.py:308] Loading weights took 0.91 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:04 [steer_vector_model_runner_mixin.py:36] Initialized SteerVector worker manager\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:04 [steer_vector_model_runner_mixin.py:50] Wrapping model with steer vector support\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m WARNING 01-11 22:12:04 [models.py:483] No moe_layer modules found for steer vector intervention\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:04 [capture_model_runner_mixin.py:113] [Capture] Wrapped 28 decoder layers for hidden states capture\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:04 [gpu_model_runner.py:3731] Model loading took 2.8876 GiB memory and 2.020775 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:07 [gpu_worker.py:376] Available KV cache memory: 37.72 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:07 [kv_cache_utils.py:1309] GPU KV cache size: 1,412,400 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:07 [kv_cache_utils.py:1314] Maximum concurrency for 32,768 tokens per request: 43.10x\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:07 [core.py:260] init engine (profile, create kv cache, warmup model) took 2.58 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m WARNING 01-11 22:12:07 [vllm.py:632] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=165357)\u001b[0;0m INFO 01-11 22:12:08 [vllm.py:725] Cudagraph is disabled under eager mode\n",
      "INFO 01-11 22:12:08 [llm.py:361] Supported tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vllm.steer_vectors.request import SteerVectorRequest\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "llm = LLM(\n",
    "    model=\"/home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\",\n",
    "    enable_steer_vector=True,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1,\n",
    "    enable_chunked_prefill=False\n",
    ")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/home/shenyl/hf/model/Qwen/Qwen2.5-1.5B-Instruct/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0514ebafe4447e3a71193fbc08b31cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72278483de246b5ad70e0c9d7f82af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, outpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the greatest common divisor (GCD) of the numbers 3339, 2961, and 1491, we will use the Euclidean algorithm. The Euclidean algorithm involves repeated division and taking remainders until we reach a remainder of 0. The last non-zero remainder is the GCD.\n",
      "\n",
      "First, we find the GCD of 3339 and 2961.\n",
      "\n",
      "1. Divide 3339 by 2961 and find the remainder:\n",
      "   \\[\n",
      "   3339 = 2961 \\cdot 1 + 378\n",
      "   \\]\n",
      "   So, the remainder is 378.\n",
      "\n",
      "2. Now, we need to find the GCD of 2961 and 378. Divide 2961 by 378:\n",
      "   \\[\n",
      "   2961 = 378 \\cdot 7 + 255\n",
      "   \\]\n",
      "   So, the remainder is 255.\n",
      "\n",
      "3. Next, we find the GCD of 378 and 255. Divide 378 by 255:\n",
      "   \\[\n",
      "   378 = 255 \\cdot 1 + 123\n",
      "   \\]\n",
      "   So, the remainder is 123.\n",
      "\n",
      "4. Now, we find the GCD of 255 and 123. Divide 255 by 123:\n",
      "   \\[\n",
      "   255 = 123 \\cdot 2 + 0\n",
      "   \\]\n",
      "   So, the remainder is 0. The last non-zero remainder is 123.\n",
      "\n",
      "Thus, the GCD of 3339 and 2961 is 123.\n",
      "\n",
      "Next, we need to find the GCD of 123 and 1491.\n",
      "\n",
      "1. Divide 1491 by 123:\n",
      "   \\[\n",
      "   1491 = 123 \\cdot 12 + 15\n",
      "   \\]\n",
      "   So, the remainder is 15.\n",
      "\n",
      "2. Now, we find the GCD of 123 and 15. Divide 123 by 15:\n",
      "   \\[\n",
      "   123 = 15 \\cdot 8 + 3\n",
      "   \\]\n",
      "   So, the remainder is 3.\n",
      "\n",
      "3. Next, we find the GCD of 15 and 3. Divide 15 by 3:\n",
      "   \\[\n",
      "   15 = 3 \\cdot 5 + 0\n",
      "   \\]\n",
      "   So, the remainder is 0. The last non-zero remainder is 3.\n",
      "\n",
      "Thus, the GCD of 123 and 1491 is 3.\n",
      "\n",
      "Therefore, the greatest common divisor of 3339, 2961, and 1491 is \\(\\boxed{3}\\).\n",
      "Baseline tokens:  637\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"<|im_start|>user\\n%s<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "prompt = \"Find the greatest common divisor of $3339$, $2961$, and $1491$.\"\n",
    "text = prompt_template % prompt\n",
    "\n",
    "output = llm.generate(\n",
    "    text,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    ")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Baseline tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49528139854a4e92bf1a69c4b01d92b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2197a25b1f476295191d1cca56d925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, outpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the greatest common divisor (GCD) of the numbers 3339, 2961, and 1491, we will use the Euclidean algorithm. The Euclidean algorithm is a method for finding the GCD of two numbers by repeatedly applying the division algorithm. We will first find the GCD of 3339 and 2961, and then use that result to find the GCD with 1491.\n",
      "\n",
      "### Step 1: Find the GCD of 3339 and 2961\n",
      "\n",
      "1. **Apply the Euclidean algorithm:**\n",
      "   - Start with the two numbers: 3339 and 2961.\n",
      "   - Divide 3339 by 2961 and find the remainder:\n",
      "     \\[\n",
      "     3339 \\div 2961 \\approx 1.12 \\quad \\text{(not an integer, so we need to adjust)}\n",
      "     \\]\n",
      "     Let's try a different approach. Instead, let's start with the Euclidean algorithm directly:\n",
      "     \\[\n",
      "     3339 = 2961 \\times 1 + 378\n",
      "     \\]\n",
      "     \\[\n",
      "     2961 = 378 \\times 7 + 375\n",
      "     \\]\n",
      "     \\[\n",
      "     378 = 375 \\times 1 + 3\n",
      "     \\]\n",
      "     \\[\n",
      "     375 = 3 \\times 125 + 0\n",
      "     \\]\n",
      "     Now, we have reached a remainder of 0. The last non-zero remainder is 3, which means:\n",
      "     \\[\n",
      "     \\text{GCD}(3339, 2961) = 3\n",
      "     \\]\n",
      "\n",
      "2. **Now, find the GCD of 3 and 1491:**\n",
      "   - Start with the two numbers: 3 and 1491.\n",
      "   - Divide 1491 by 3 and find the remainder:\n",
      "     \\[\n",
      "     1491 \\div 3 = 497 \\quad \\text{(no remainder)}\n",
      "     \\]\n",
      "     \\[\n",
      "     1491 = 3 \\times 497 + 0\n",
      "     \\]\n",
      "     Now, we have reached a remainder of 0. The last non-zero remainder is 3, which means:\n",
      "     \\[\n",
      "     \\text{GCD}(3, 1491) = 3\n",
      "     \\]\n",
      "\n",
      "### Step 2: Combine the results\n",
      "\n",
      "The GCD of 3339 and 2961 is 3. Now, we need to find the GCD of 3 and 1491. Since the GCD of 3 and 3 is 3, we can conclude that:\n",
      "\n",
      "\\[\n",
      "\\text{GCD}(3339, 2961, 1491) = 3\n",
      "\\]\n",
      "\n",
      "Thus, the greatest common divisor of 3339, 2961, and 1491 is \\(\\boxed{3}\\).\n",
      "Slow tokens:  672\n"
     ]
    }
   ],
   "source": [
    "steer_vector_request_pos = SteerVectorRequest(\n",
    "    steer_vector_name=\"thinking_switch_pos\",\n",
    "    steer_vector_int_id=1,\n",
    "    steer_vector_local_path=\"MATH500.gguf\",\n",
    "    scale=2.0,\n",
    "    prefill_trigger_tokens=[-1],\n",
    "    generate_trigger_tokens=[-1],\n",
    "    debug=False,\n",
    "    algorithm='direct',\n",
    "    target_layers=list(range(28))\n",
    ")\n",
    "output = llm.generate(\n",
    "    text,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    "    steer_vector_request=steer_vector_request_pos\n",
    ")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Slow tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993db0f078b648ba8c14ee26ef6cd4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed75ad4a0f794c23be299d48a05f09f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, outpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the greatest common divisor (GCD) of \\(3339\\), \\(2961\\), and \\(1491\\), we start by finding the GCD of the first two numbers, and then check if this GCD divides the third number.\n",
      "\n",
      "First, we find the GCD of \\(3339\\) and \\(2961\\). We use the Euclidean algorithm:\n",
      "\\[3339 = 2961 \\cdot 1 + 378,\\]\n",
      "\\[2961 = 378 \\cdot 7 + 363,\\]\n",
      "\\[378 = 363 \\cdot 1 + 15,\\]\n",
      "\\[363 = 15 \\cdot 24 + 3,\\]\n",
      "\\[15 = 3 \\cdot 5 + 0.\\]\n",
      "Thus, the GCD of \\(3339\\) and \\(2961\\) is \\(3\\).\n",
      "\n",
      "Next, we check if \\(3\\) divides \\(1491\\). Since \\(1491 = 3 \\cdot 497\\), \\(3\\) divides \\(1491\\).\n",
      "\n",
      "Therefore, the GCD of \\(3339\\), \\(2961\\), and \\(1491\\) is \\(3\\).\n",
      "\n",
      "The answer is \\(\\boxed{3}\\).\n",
      "Fast tokens:  292\n"
     ]
    }
   ],
   "source": [
    "steer_vector_request_neg = SteerVectorRequest(\n",
    "    steer_vector_name=\"thinking_switch_neg\",\n",
    "    steer_vector_int_id=2,\n",
    "    steer_vector_local_path=\"MATH500.gguf\",\n",
    "    scale=-2.0,\n",
    "    prefill_trigger_tokens=[-1],\n",
    "    generate_trigger_tokens=[-1],\n",
    "    debug=False,\n",
    "    algorithm='direct',\n",
    "    target_layers=list(range(28))\n",
    ")\n",
    "output = llm.generate(\n",
    "    text,\n",
    "    SamplingParams(\n",
    "        temperature=0,\n",
    "        max_tokens=4096,\n",
    "        skip_special_tokens=False,\n",
    "    ),\n",
    "    steer_vector_request=steer_vector_request_neg\n",
    ")\n",
    "print(output[0].outputs[0].text)\n",
    "print(\"Fast tokens: \", len(tokenizer.tokenize(output[0].outputs[0].text, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
