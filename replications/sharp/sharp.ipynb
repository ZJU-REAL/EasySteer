{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb42e4-3a6e-47e5-ab89-4839c6a03ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from vllm.steer_vectors.request import SteerVectorRequest\n",
    "import os\n",
    "\n",
    "# Set your GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "os.environ[\"NCCL_DEBUG\"] = \"ERROR\" \n",
    "os.environ[\"NCCL_DEBUG_FILE\"] = \"/dev/null\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\"\n",
    "os.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"\n",
    "\n",
    "# Initialize the LLM model\n",
    "# enable_steer_vector=True: Enables vector steering (without this, behaves like regular vLLM)\n",
    "# enforce_eager=True: Ensures reliability and stability of interventions (strongly recommended)\n",
    "model_id = \"llava-hf/llava-v1.6-vicuna-7b-hf\"\n",
    "llm = LLM(\n",
    "    model=model_id,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1,\n",
    "    enable_chunked_prefill=False,\n",
    "    enable_steer_vector=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141c8565-27b8-49a4-a803-35269a6e05b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlavaNextProcessor\n",
    "from PIL import Image\n",
    "paths = [\"test.jpg\"]\n",
    "images = [Image.open(p) for p in paths]\n",
    "tokenizer = LlavaNextProcessor.from_pretrained(model_id)\n",
    "\n",
    "question = \"Is there a parking meter in the image?\"\n",
    "messages_list = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                [{\"type\": \"image\"}] + [{\"type\": \"text\", \"text\": question}]\n",
    "            ),\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "mm_prompts = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    for messages in messages_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c0861b-ee65-4755-8ea7-8ffe47a2d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: <image>\n",
      "Is there a parking meter in the image? ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(mm_prompts[0])\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.0,\n",
    "    max_tokens=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9dbee99-e924-4b4b-8add-5b1f1f3e6a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s, est. speed input: 2722.62 toks/s, output: 45.83 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, there is a parking meter in the image. It is located on the sidewalk next to the street.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(\n",
    "    {\n",
    "        \"prompt\": mm_prompts[0],\n",
    "        \"multi_modal_data\": {\"image\": images},\n",
    "    },\n",
    "    sampling_params=sampling_params,\n",
    ")\n",
    "print(outputs[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf88f4ac-932a-493b-832d-dd40a23ba72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted task_vector_layer-10.npy to task_vector_layer-10.pt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# .npy -> .pt\n",
    "npy_file_path = \"task_vector_layer-10.npy\"\n",
    "pt_file_path = \"task_vector_layer-10.pt\"\n",
    "data = np.load(npy_file_path)\n",
    "tensor_data = torch.from_numpy(data)\n",
    "torch.save(tensor_data, pt_file_path)\n",
    "\n",
    "print(f\"Successfully converted {npy_file_path} to {pt_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9aaed49-2a56-48bc-9fdd-23985ba115ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 512.19it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s, est. speed input: 2681.05 toks/s, output: 57.77 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, there is no parking meter visible in the image. The image shows a street scene with a building, traffic lights, and a street sign.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steer_request = SteerVectorRequest(\n",
    "    \"1\", \n",
    "    1,\n",
    "    steer_vector_local_path=\"task_vector_layer-10.pt\",\n",
    "    scale=6,\n",
    "    target_layers=[10], \n",
    "    prefill_trigger_positions=[-1], \n",
    "    generate_trigger_tokens=[-1],\n",
    ")\n",
    "steer_output = llm.generate(\n",
    "    {\n",
    "        \"prompt\": mm_prompts[0],\n",
    "        \"multi_modal_data\": {\"image\": images},\n",
    "    },\n",
    "    steer_vector_request=steer_request,\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "print(steer_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4e4ed-34b0-4b8e-91de-dc4e6a6fc365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easysteer",
   "language": "python",
   "name": "easysteer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
